[
  {
    "objectID": "citations.html",
    "href": "citations.html",
    "title": "Citations",
    "section": "",
    "text": "Alipour, F., Holmes, C., Lu, Y. Y., Hill, K. A., & Kari, L. (2024). Leveraging machine learning for taxonomic classification of emerging astroviruses. Frontiers in Molecular Biosciences, 10. https://doi.org/10.3389/fmolb.2023.1305506\nAnimal. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Animal&oldid=1306191709\nCollins, A. G., Cartwright, P., McFadden, C. S., & Schierwater, B. (2005). Phylogenetic Context and Basal Metazoan Model Systems. Integrative and Comparative Biology, 45(4), 585–594. https://doi.org/10.1093/icb/45.4.585\nDeuterostome. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Deuterostome&oldid=1299664913\nEcdysozoa. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Ecdysozoa&oldid=1305526962\nLophotrochozoa. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Lophotrochozoa&oldid=1302526625\nTessler, M., Neumann, J. S., Kamm, K., Osigus, H.-J., Eshel, G., Narechania, A., Burns, J. A., DeSalle, R., & Schierwater, B. (2022). Phylogenomics and the first higher taxonomy of Placozoa, an ancient and enigmatic animal phylum. Frontiers in Ecology and Evolution, 10. https://doi.org/10.3389/fevo.2022.1016357\nvan der Gulik, P. T. S., Hoff, W. D., & Speijer, D. (2023). Renewing Linnaean taxonomy: A proposal to restructure the highest levels of the Natural System. Biological Reviews, 98(2), 584–602. https://doi.org/10.1111/brv.12920"
  },
  {
    "objectID": "citations.html#all-sources-apa",
    "href": "citations.html#all-sources-apa",
    "title": "Citations",
    "section": "",
    "text": "Alipour, F., Holmes, C., Lu, Y. Y., Hill, K. A., & Kari, L. (2024). Leveraging machine learning for taxonomic classification of emerging astroviruses. Frontiers in Molecular Biosciences, 10. https://doi.org/10.3389/fmolb.2023.1305506\nAnimal. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Animal&oldid=1306191709\nCollins, A. G., Cartwright, P., McFadden, C. S., & Schierwater, B. (2005). Phylogenetic Context and Basal Metazoan Model Systems. Integrative and Comparative Biology, 45(4), 585–594. https://doi.org/10.1093/icb/45.4.585\nDeuterostome. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Deuterostome&oldid=1299664913\nEcdysozoa. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Ecdysozoa&oldid=1305526962\nLophotrochozoa. (2025). In Wikipedia. https://en.wikipedia.org/w/index.php?title=Lophotrochozoa&oldid=1302526625\nTessler, M., Neumann, J. S., Kamm, K., Osigus, H.-J., Eshel, G., Narechania, A., Burns, J. A., DeSalle, R., & Schierwater, B. (2022). Phylogenomics and the first higher taxonomy of Placozoa, an ancient and enigmatic animal phylum. Frontiers in Ecology and Evolution, 10. https://doi.org/10.3389/fevo.2022.1016357\nvan der Gulik, P. T. S., Hoff, W. D., & Speijer, D. (2023). Renewing Linnaean taxonomy: A proposal to restructure the highest levels of the Natural System. Biological Reviews, 98(2), 584–602. https://doi.org/10.1111/brv.12920"
  },
  {
    "objectID": "citations.html#libraries-citations",
    "href": "citations.html#libraries-citations",
    "title": "Citations",
    "section": "Libraries Citations",
    "text": "Libraries Citations\n\nNumPy documentation—NumPy v2.2 Manual. (n.d.). Retrieved August 20, 2025, from https://numpy.org/doc/2.2/\nos—Miscellaneous operating system interfaces. (n.d.). Python Documentation. Retrieved August 20, 2025, from https://docs.python.org/3/library/os.html\npandas documentation—Pandas 2.2.3 documentation. (n.d.). Retrieved August 20, 2025, from https://pandas.pydata.org/pandas-docs/version/2.2/\nPython 3.12 documentation. (n.d.). Python Documentation. Retrieved August 20, 2025, from https://docs.python.org/3/\nScikit-learn: Machine learning in Python—Scikit-learn 1.7.1 documentation. (n.d.). Retrieved August 20, 2025, from https://scikit-learn.org/stable/\nTeam, T. M. D. (2025). Matplotlib: Visualization with Python [Computer software]. Zenodo. https://doi.org/10.5281/zenodo.14940554\nWaskom, M. L. (2021). seaborn: Statistical data visualization. Journal of Open Source Software, 6(60), 3021. https://doi.org/10.21105/joss.03021\nWelcome to the SHAP documentation—SHAP latest documentation. (n.d.). Retrieved August 20, 2025, from https://shap.readthedocs.io/en/latest/"
  },
  {
    "objectID": "presentation.html#motivation-questions",
    "href": "presentation.html#motivation-questions",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "Motivation & Questions",
    "text": "Motivation & Questions\n\nObjectivesResearch Questions\n\n\n\nChallenges in classification (Tessler et al., 2022; van der Gulik et al., 2023)\n\nMachine learning for taxonomy is new, needs evaluation (Alipour et al., 2024)\n\nPotential: narrow candidate taxa and save time\n\n\n\n\nHow accurately can a machine learning model classify animal taxa based on the binary presence of sexually selected traits?\n\nDo evolutionary origin rates of sexual traits provide stronger predictive power than binary trait presence when classifying animal taxa?"
  },
  {
    "objectID": "presentation.html#eda---family",
    "href": "presentation.html#eda---family",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "EDA - Family",
    "text": "EDA - Family\n\nDistributionPrevalenceBinary Presence"
  },
  {
    "objectID": "presentation.html#eda-evolution",
    "href": "presentation.html#eda-evolution",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "EDA — Evolution",
    "text": "EDA — Evolution\n\nSkewnessDistributionPrevalence\n\n\n\n\n\n=== Skewness ===\nA    :  3.5053\nG    :  9.0968\nO    :  3.3938\nT    :  4.4907\nV    :  4.2405\nC    :  3.4515\nF    :  3.4248\nK    :  4.0070\nM    :  3.8618\nS    :  5.0951"
  },
  {
    "objectID": "presentation.html#modeling-approach",
    "href": "presentation.html#modeling-approach",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "Modeling Approach",
    "text": "Modeling Approach\n\nData PreprocessingData Preprocessing (Continued)Modeling ApproachesEvaluation Metrics\n\n\nTarget encoding - Created feature: Superphylum (label-encoded, 5 groups)\n\n\n\nEcdysozoa\nLophotrochozoa\nDeuterostomia\n\n\n\nBasal Metazoa & Non-Bilaterians\nBasal Bilateria\n\n\n\n\n\nFamily dataset\n\nBinary trait presence (0/1) kept\nClass weights applied\n\nEvolution dataset\n\nTrait rates log-transformed (log1p)\n\n\n\n\n\n\n\nStandardized features (skewness)\nTrain/test split = 1/3\nStratified by superphyla\n\n\n\nExcluded ID & class columns\nModels:\n\nLogistic Regression\nRandom Forest\nDecision Tree\n\n\n\n\n\n\nAccuracy (overall correct)\nBalanced Accuracy (avg recall per class)\nMacro F1 (avg F1 per class)"
  },
  {
    "objectID": "presentation.html#results",
    "href": "presentation.html#results",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "Results",
    "text": "Results\n\nFamilyEvolutionComparison\n\n\n\n\n=== FAMILY (Superphylum) RESULTS ===\n\nDecision Tree: acc=0.147 | bal_acc=0.280 | macro-F1=0.087\n              precision    recall  f1-score   support\n\n           0       0.01      1.00      0.01         1\n           1       0.00      0.00      0.00         2\n           2       0.12      0.25      0.16        12\n           3       0.93      0.15      0.26       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.15       218\n   macro avg       0.21      0.28      0.09       218\nweighted avg       0.80      0.15      0.23       218\n\nConfusion matrix:\n [[  1   0   0   0   0]\n [  2   0   0   0   0]\n [  8   0   3   1   0]\n [136   0  22  28   0]\n [ 16   0   0   1   0]]\n\nRandom Forest: acc=0.229 | bal_acc=0.283 | macro-F1=0.128\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.01      1.00      0.02         2\n           2       0.33      0.17      0.22        12\n           3       0.94      0.25      0.39       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.23       218\n   macro avg       0.26      0.28      0.13       218\nweighted avg       0.82      0.23      0.35       218\n\nConfusion matrix:\n [[  0   1   0   0   0]\n [  0   2   0   0   0]\n [  0   8   2   2   0]\n [  0 136   4  46   0]\n [  0  16   0   1   0]]\n\nLogistic Regression: acc=0.220 | bal_acc=0.296 | macro-F1=0.132\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.01      1.00      0.02         2\n           2       0.27      0.25      0.26        12\n           3       0.98      0.23      0.37       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.22       218\n   macro avg       0.25      0.30      0.13       218\nweighted avg       0.85      0.22      0.33       218\n\nConfusion matrix:\n [[  0   1   0   0   0]\n [  0   2   0   0   0]\n [  0   8   3   1   0]\n [  0 136   7  43   0]\n [  0  16   1   0   0]]\n\n[FAMILY Superphylum] RF 4-fold CV macro-F1: 0.109 ± 0.011\n\n\n\n\n\n\n\n=== EVOLUTION RESULTS ===\n\nDecision Tree: acc=0.143 | bal_acc=0.229 | macro-F1=0.093\n              precision    recall  f1-score   support\n\n           0       0.12      1.00      0.21         3\n           1       0.00      0.00      0.00         4\n           2       0.00      0.00      0.00         3\n           3       1.00      0.14      0.25         7\n           4       0.00      0.00      0.00        11\n\n    accuracy                           0.14        28\n   macro avg       0.22      0.23      0.09        28\nweighted avg       0.26      0.14      0.09        28\n\nConfusion matrix:\n [[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  0  0  1]\n [ 5  0  1  1  0]\n [11  0  0  0  0]]\n\nRandom Forest: acc=0.214 | bal_acc=0.324 | macro-F1=0.232\n              precision    recall  f1-score   support\n\n           0       0.12      1.00      0.21         3\n           1       0.00      0.00      0.00         4\n           2       1.00      0.33      0.50         3\n           3       1.00      0.29      0.44         7\n           4       0.00      0.00      0.00        11\n\n    accuracy                           0.21        28\n   macro avg       0.42      0.32      0.23        28\nweighted avg       0.37      0.21      0.19        28\n\nConfusion matrix:\n [[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  1  0  0]\n [ 5  0  0  2  0]\n [11  0  0  0  0]]\n\nLogistic Regression: acc=0.500 | bal_acc=0.324 | macro-F1=0.311\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         3\n           1       0.00      0.00      0.00         4\n           2       1.00      0.33      0.50         3\n           3       1.00      0.29      0.44         7\n           4       0.44      1.00      0.61        11\n\n    accuracy                           0.50        28\n   macro avg       0.49      0.32      0.31        28\nweighted avg       0.53      0.50      0.40        28\n\nConfusion matrix:\n [[ 0  0  0  0  3]\n [ 0  0  0  0  4]\n [ 0  0  1  0  2]\n [ 0  0  0  2  5]\n [ 0  0  0  0 11]]\n\n\n\n[EVOLUTION] RF 5-fold CV macro-F1: 0.193 ± 0.065\n\n\n\n\n\n\n\n=== FAMILY vs EVOLUTION — MODEL COMPARISON ===\n                          acc          bal_acc         macro_F1       \ndataset             evolution family evolution family evolution family\nmodel                                                                 \nDecision Tree           0.143  0.147     0.229  0.280     0.093  0.087\nLogistic Regression     0.500  0.220     0.324  0.296     0.311  0.132\nRandom Forest           0.214  0.229     0.324  0.283     0.232  0.128"
  },
  {
    "objectID": "presentation.html#shap-interpretation",
    "href": "presentation.html#shap-interpretation",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "SHAP Interpretation",
    "text": "SHAP Interpretation\n\nF - PlotF - ScoresE - PlotE - Scores\n\n\n\n\n\n\n\n\n[SHAP] Random Forest — FAMILY\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[SHAP] FAMILY — top features by average absolute contribution\n 1. SS  —  mean|SHAP|=0.1858\n 2. F  —  mean|SHAP|=0.1131\n 3. T  —  mean|SHAP|=0.0595\n 4. C  —  mean|SHAP|=0.0525\n 5. M  —  mean|SHAP|=0.0441\n 6. V  —  mean|SHAP|=0.0289\n 7. O  —  mean|SHAP|=0.0192\n 8. A  —  mean|SHAP|=0.0158\n 9. G  —  mean|SHAP|=0.0062\n10. S  —  mean|SHAP|=0.0026\n\n\n\n\n\n\n\n[SHAP] Random Forest — EVOLUTION (global)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[SHAP] EVOLUTION — top features by average absolute contribution\n 1. V  —  mean|SHAP|=0.0802\n 2. C  —  mean|SHAP|=0.0550\n 3. A  —  mean|SHAP|=0.0398\n 4. F  —  mean|SHAP|=0.0365\n 5. K  —  mean|SHAP|=0.0310\n 6. M  —  mean|SHAP|=0.0309\n 7. O  —  mean|SHAP|=0.0262\n 8. T  —  mean|SHAP|=0.0190\n 9. G  —  mean|SHAP|=0.0111\n10. S  —  mean|SHAP|=0.0089"
  },
  {
    "objectID": "presentation.html#conclusion",
    "href": "presentation.html#conclusion",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "Conclusion",
    "text": "Conclusion\n\nConclusion: evolution has stronger overall predictive power than family (binary)\nFuture works or potential applications:\n\nRemove SS traits and redo modeling for family\nImprove data quality\nSHAP applications to biological interpretations"
  },
  {
    "objectID": "presentation.html#thank-you-for-listening",
    "href": "presentation.html#thank-you-for-listening",
    "title": "Predicting Animal Phyla from Sexually Selected Traits",
    "section": "Thank you for listening!",
    "text": "Thank you for listening!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project was developed by BioCurio For INFO 523 - Data Mining and Discovery at the University of Arizona, taught by Dr. Greg Chism. The team is comprised of the following team members.\n\nMatthew Qi Lan Thompson: Currently first year in a Masters for Data Science Online program with a bachelor degree for Biology B.S. and a minor in Data Science."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abstract",
    "section": "",
    "text": "This project evaluates whether sexually selected traits can be used to classify animal taxa with machine learning, comparing binary presence/absence data against evolutionary origin rates. To reduce sparsity, phyla were grouped into five superphyla and modeled with decision trees, random forests, and logistic regression, using balanced accuracy and macro F1 to account for uneven classes. Exploratory analysis showed the binary dataset was sparse and dominated by Arthropoda, limiting predictive power, while the evolutionary dataset was more balanced but skewed and correlated. Results indicated that binary data performed poorly across all models, whereas evolutionary rates provided stronger signal, with logistic regression achieving the highest accuracy and macro F1. SHAP analysis confirmed that binary models relied almost entirely on the “sexually selected” flag, while evolutionary models distributed importance across visual, competition, auditory, and female choice traits. Overall, evolutionary rates offered more predictive value than binary presence. Problems seen in modelings would suggest the need for improved data quality and modeling approaches."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Abstract",
    "section": "Introduction",
    "text": "Introduction\nIntroduction\nClassifying animals was pretty challenging due to boundaries blur across body plans, life histories, and genomes, and even well-sampled groups can be tricky. I wanted to see how far standard machine-learning methods can go when asked a simple question: can sexually selected traits predict higher-level groups, and which traits matter most? This project tests that idea and compares two kinds of signal—presence/absence style traits versus rate-style traits—to see which carries more predictive power.\nMethodology\nTo cut sparsity and keep results readable, I group many phyla into five superphyla for modeling only: - Ecdysozoa - Lophotrochozoa - Deuterostomia - Basal Metazoa & Non-Bilaterians - Basal Bilateria.\nI will use the following: Logistic Regression, Decision Trees, and Random Forest, and use SHAP to check what these classifiers actually use to make decisions. But, to clarify, the focus is not to replace phylogenetics or other classification methods for animal-related scientist roles, but to gauge what models add, where models break, and how the setup could be improved.\nPotential\nIf the approach proves useful, it could guide follow-up work, streamline handling of ambiguous cases when classifying, and point to better trait design or data collection for future studies."
  },
  {
    "objectID": "index.html#full-data-analysis",
    "href": "index.html#full-data-analysis",
    "title": "Abstract",
    "section": "Full Data Analysis",
    "text": "Full Data Analysis\n\nImported Libraries\nHere are all the imported libraries needed to do the full data analysis below:\n\n\nCode\nimport numpy as np              # numbers, arrays, math\nimport pandas as pd             # tables, csv loading, data handling\nimport os    \nimport matplotlib.pyplot as plt   # plotting\nimport shap                       # shap values for model explainability\nimport seaborn as sns\n\nfrom sklearn.tree import DecisionTreeClassifier       # decision tree model\nfrom sklearn.ensemble import RandomForestClassifier   # random forest model\nfrom sklearn.linear_model import LogisticRegression   # logistic regression model\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import cross_val_score   # cross validation scoring\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, balanced_accuracy_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n#note: micromamba activate data_science_foundation to pip install and resolve shap issues\n\n\nLibraries version below:\n\n\nCode\nimport sys, json\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport shap\nimport sklearn\n\nversions = {\n    \"python\": sys.version.split()[0],\n    \"numpy\": np.__version__,\n    \"pandas\": pd.__version__,\n    \"matplotlib\": matplotlib.__version__,\n    \"seaborn\": sns.__version__,\n    \"scikit-learn\": sklearn.__version__,\n    \"shap\": shap.__version__,\n    \"os\": \"stdlib\",   # standard library; no version\n}\n\nprint(json.dumps(versions, indent=2))\n\n\n{\n  \"python\": \"3.12.9\",\n  \"numpy\": \"2.2.4\",\n  \"pandas\": \"2.2.2\",\n  \"matplotlib\": \"3.10.1\",\n  \"seaborn\": \"0.13.2\",\n  \"scikit-learn\": \"1.7.1\",\n  \"shap\": \"0.48.0\",\n  \"os\": \"stdlib\"\n}\n\n\n\n\n\nEDA Assessments\n\nLoading Data\n\n\nCode\n#making a function to load the data (from HW 03-04)\n\n#prompt the input for file path then load the data\ndef load_data():\n    try:\n        folder_name = input(\"Enter the folder path: \") #copy the path of the folder (right clicked data folder and copy path)\n        file_list = [f for f in os.listdir(folder_name) if f.endswith('.csv')] #searches files with csv extension in that folder\n        print(f\"Files found in {folder_name}: {file_list}\") #lists all matching files\n        \n        for file in file_list: #tries to load each file into each variable separately\n            var_name = os.path.splitext(file)[0]  #'customers' from 'customers.csv' for example\n            globals()[var_name] = pd.read_csv(os.path.join(folder_name, file)) #set each file name as a variable\n            print(f\"Loaded {file} as variable '{var_name}'\")\n            \n    except FileNotFoundError: #error handling\n        print(f\"Folder '{folder_name}' not found.\")\n        return None\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        return None\n    return True \n\n#calling the function (copy data folder entire path into the prompt box)\nload_data()\n\n\nFiles found in /Users/matthewthompson/Documents/Academics/DS Masters Academics/Data Mining and Discovery/Assignments/final-project-thompson/data: ['family_related_data.csv', 'animals_rateof_evolution.csv']\nLoaded family_related_data.csv as variable 'family_related_data'\nLoaded animals_rateof_evolution.csv as variable 'animals_rateof_evolution'\n\n\nTrue\n\n\nTwo named df: - family_related_data - animals_rateof_evolution\n\n\nCode\nfamily_df = family_related_data  \nevolution_df = animals_rateof_evolution\n\n\nRenamed to family_df and evolution_df for simplicity\n\n\nCode\nprint(family_df.info())\n\nprint(evolution_df.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1087 entries, 0 to 1086\nData columns (total 13 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Tree_Label  1087 non-null   object\n 1   Phylum      1087 non-null   object\n 2   SS          1087 non-null   int64 \n 3   A           1087 non-null   int64 \n 4   G           1087 non-null   int64 \n 5   O           1087 non-null   int64 \n 6   T           1087 non-null   int64 \n 7   V           1087 non-null   int64 \n 8   C           1087 non-null   int64 \n 9   F           1087 non-null   int64 \n 10  K           1087 non-null   int64 \n 11  M           1087 non-null   int64 \n 12  S           1087 non-null   int64 \ndtypes: int64(11), object(2)\nmemory usage: 110.5+ KB\nNone\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 84 entries, 0 to 83\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Tree    84 non-null     int64  \n 1   Phylum  84 non-null     object \n 2   A       84 non-null     float64\n 3   G       84 non-null     float64\n 4   O       84 non-null     float64\n 5   T       84 non-null     float64\n 6   V       84 non-null     float64\n 7   C       84 non-null     float64\n 8   F       84 non-null     float64\n 9   K       84 non-null     float64\n 10  M       84 non-null     float64\n 11  S       84 non-null     float64\ndtypes: float64(10), int64(1), object(1)\nmemory usage: 8.0+ KB\nNone\n\n\nFamily dataset)\nThis dataset has 1,087 rows and 13 columns, containing tree labels, phylum information, and 11 integer-coded traits which are essentially binary.\nEvolution dataset)\nThis dataset is much smaller with 84 rows and 12 columns, including phylum and traits stored as floats for continuous values (for the evolutionary rates).\nIMPORTANT NOTE\nAccording to the metadata: these floats in the evolution dataset are actually model-derived (obtained by maximum likelihood analysis)\n\n\nFamily EDA Assessments\n\n\nCode\n###### SHAPE AND INFO\n\n#family dataset below\ndf1 = family_df.copy()\ndataset_name = \"family_df\"\n\n# quick overview\nprint(f\"\\n=== {dataset_name} EDA ===\")\nprint(f\"Shape: {df1.shape[0]} rows × {df1.shape[1]} columns\")\nprint(\"\\nColumns:\", list(df1.columns))\nprint(\"\\nDtypes:\\n\", df1.dtypes)\n\n# pick likely target + trait columns\nall_traits = ['SS','A','G','O','T','V','C','F','K','M','S']\ntraits_present = [c for c in all_traits if c in df1.columns]\ntarget_col = 'Phylum' if 'Phylum' in df1.columns else None\nid_cols = [c for c in ['Tree_Label'] if c in df1.columns]\n\n#prints out the shape below\nprint(\"\\nTarget column:\", target_col)\nprint(\"Trait columns:\", traits_present)\nprint(\"ID columns:\", id_cols)\n\n\n\n=== family_df EDA ===\nShape: 1087 rows × 13 columns\n\nColumns: ['Tree_Label', 'Phylum', 'SS', 'A', 'G', 'O', 'T', 'V', 'C', 'F', 'K', 'M', 'S']\n\nDtypes:\n Tree_Label    object\nPhylum        object\nSS             int64\nA              int64\nG              int64\nO              int64\nT              int64\nV              int64\nC              int64\nF              int64\nK              int64\nM              int64\nS              int64\ndtype: object\n\nTarget column: Phylum\nTrait columns: ['SS', 'A', 'G', 'O', 'T', 'V', 'C', 'F', 'K', 'M', 'S']\nID columns: ['Tree_Label']\n\n\nThe family_df dataset has 1,087 rows and 13 columns, where Phylum is the categorical target, 11 numeric trait columns (SS–S) are features (binary), and Tree_Label acts as an identifier. This makes it well-structured for classification tasks predicting phylum from trait patterns.\n\n\nCode\n##### SUMMARY INFO numerics and categoricals\n\n# numeric & categorical summaries:\nnumeric_df = df1.select_dtypes(include='number')\ncat_df = df1.select_dtypes(include=['object','category'])\n\n#prints summaries below\nif not numeric_df.empty:\n    print(\"\\nSummary (numeric):\\n\", numeric_df.describe().T)\nelse:\n    print(\"\\nNo numeric columns for numeric summary.\")\n\nif not cat_df.empty:\n    print(\"\\nSummary (categorical):\\n\", cat_df.describe().T)\nelse:\n    print(\"\\nNo categorical columns for categorical summary.\")\n\n\n\nSummary (numeric):\n      count      mean       std  min  25%  50%  75%  max\nSS  1087.0  0.269549  0.443930  0.0  0.0  0.0  1.0  1.0\nA   1087.0  0.037718  0.190602  0.0  0.0  0.0  0.0  1.0\nG   1087.0  0.021159  0.143981  0.0  0.0  0.0  0.0  1.0\nO   1087.0  0.103036  0.304146  0.0  0.0  0.0  0.0  1.0\nT   1087.0  0.131555  0.338162  0.0  0.0  0.0  0.0  1.0\nV   1087.0  0.093836  0.291735  0.0  0.0  0.0  0.0  1.0\nC   1087.0  0.109476  0.312379  0.0  0.0  0.0  0.0  1.0\nF   1087.0  0.181233  0.385388  0.0  0.0  0.0  0.0  1.0\nK   1087.0  0.007360  0.085512  0.0  0.0  0.0  0.0  1.0\nM   1087.0  0.107636  0.310062  0.0  0.0  0.0  0.0  1.0\nS   1087.0  0.015639  0.124133  0.0  0.0  0.0  0.0  1.0\n\nSummary (categorical):\n            count unique          top freq\nTree_Label  1087   1087    1Laevipil    1\nPhylum      1087     29  Arthropoda   917\n\n\nThe numeric traits are mostly binary (0/1) with low mean values, showing that most traits are absent in most samples, except SS (27%) and F (18%), which occur more frequently (sum of 1s divided by total value). Categorical data shows each Tree_Label is unique, and the dataset is highly imbalanced, with Arthropoda dominating (917 of 1087, ~84%) among the 29 phyla for ‘Phylum’.\n\n\nCode\n# missing values\nna = df1.isna().sum()\nna = na[na &gt; 0]\n\n#if any NA, prints error otherwise missing values\nif na.empty:\n    print(\"\\nNo missing values detected.\")\nelse:\n    print(\"\\nColumns with nulls:\\n\", na)\n    print(\"\\nNull %:\\n\", (na/len(df)*100).round(2))\n\n\n\nNo missing values detected.\n\n\n\n\nCode\n# unique counts\nprint(\"\\nUnique values per column:\\n\", df1.nunique())\n\n\n\nUnique values per column:\n Tree_Label    1087\nPhylum          29\nSS               2\nA                2\nG                2\nO                2\nT                2\nV                2\nC                2\nF                2\nK                2\nM                2\nS                2\ndtype: int64\n\n\n\n\nCode\n#outlier scan (IQR) – skip pure binary columns\nprint(\"\\nOutlier scan (IQR):\")\nfor col in numeric_df.columns:\n    vals = df1[col].dropna().unique()\n    #treat as binary if values subset of {0,1}\n    if set(vals).issubset({0,1,0.0,1.0}):\n        print(f\"{col}: skipped (binary)\")\n        continue\n    Q1 = df1[col].quantile(0.25)\n    Q3 = df1[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lo = Q1 - 1.5*IQR\n    hi = Q3 + 1.5*IQR\n    mask = (df1[col] &lt; lo) | (df1[col] &gt; hi) #mark values below Q1−1.5*IQR or above Q3+1.5*IQR as outliers\n    cnt = int(mask.sum()) #count how many outliers there are below or outside IQR\n    pct = 100*cnt/len(df1) #percentage of outliers\n    print(f\"{col}: {cnt} outliers ({pct:.2f}%)\") #reports outlier count and %\n\n\n\nOutlier scan (IQR):\nSS: skipped (binary)\nA: skipped (binary)\nG: skipped (binary)\nO: skipped (binary)\nT: skipped (binary)\nV: skipped (binary)\nC: skipped (binary)\nF: skipped (binary)\nK: skipped (binary)\nM: skipped (binary)\nS: skipped (binary)\n\n\nSince all trait columns are binary (0/1), an IQR-based outlier scan is not applicable — there are no true numeric outliers in this dataset. The traits can only vary by presence/absence, not by extreme values\n\n\nCode\n# Skewness\nif not numeric_df.empty:\n    with np.errstate(all='ignore'):\n        skew_vals = numeric_df.drop(columns=id_cols, errors='ignore').skew(numeric_only=True)\n\n        print(\"\\n=== Skewness ===\")\n        for col, val in skew_vals.items():\n            print(f\"{col:5s}: {val: .4f}\")\nelse:\n    print(\"\\nNo numeric columns for skewness in Family dataset.\")\n\n# Kurtosis\nif not numeric_df.empty:\n    with np.errstate(all='ignore'):\n        kurt_vals = numeric_df.drop(columns=id_cols, errors='ignore').kurt(numeric_only=True)\n\n        print(\"\\n=== Kurtosis ===\")\n        for col, val in kurt_vals.items():\n            print(f\"{col:5s}: {val: .4f}\")\nelse:\n    print(\"\\nNo numeric columns for kurtosis in Family dataset.\")\n\n\n\n=== Skewness ===\nSS   :  1.0401\nA    :  4.8597\nG    :  6.6637\nO    :  2.6152\nT    :  2.1831\nV    :  2.7896\nC    :  2.5049\nF    :  1.6573\nK    :  11.5434\nM    :  2.5355\nS    :  7.8183\n\n=== Kurtosis ===\nSS   : -0.9198\nA    :  21.6564\nG    :  42.4832\nO    :  4.8480\nT    :  2.7711\nV    :  5.7925\nC    :  4.2826\nF    :  0.7481\nK    :  131.4920\nM    :  4.4371\nS    :  59.2347\n\n\nAll traits are positively skewed, meaning trait presence (1) is rare compared to absence (0). The strongest skew and highest kurtosis occur in K (female-female competition), S (intersexual conflict), and G (gustatory), showing these traits are extremely sparse, while more common traits like SS (any sexually selected trait) and F (female choice) are less skewed.\n\n\nCode\n# correlations (absolute) among numeric\nif not numeric_df.empty:\n    corr = numeric_df.corr().abs()\n    print(\"\\nCorrelation matrix (|r|):\\n\", corr)\n\nif corr is not None:\n    plt.figure(figsize=(8,6))\n    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar=True)\n    plt.title(\"Absolute Correlation Matrix (Family dataset traits)\")\n    plt.show()\n\n\n\nCorrelation matrix (|r|):\n           SS         A         G         O         T         V         C  \\\nSS  1.000000  0.315031  0.242030  0.551115  0.634572  0.529735  0.577181   \nA   0.315031  1.000000  0.138659  0.107623  0.051520  0.135007  0.100703   \nG   0.242030  0.138659  1.000000  0.097360  0.056249  0.128062  0.010604   \nO   0.551115  0.107623  0.097360  1.000000  0.100862  0.119243  0.123462   \nT   0.634572  0.051520  0.056249  0.100862  1.000000  0.294774  0.639344   \nV   0.529735  0.135007  0.128062  0.119243  0.294774  1.000000  0.453005   \nC   0.577181  0.100703  0.010604  0.123462  0.639344  0.453005  1.000000   \nF   0.763723  0.370670  0.295909  0.539708  0.375067  0.438281  0.202182   \nK   0.141746  0.039448  0.012660  0.041626  0.157547  0.119935  0.211111   \nM   0.571720  0.274021  0.134572  0.722016  0.137071  0.163090  0.039847   \nS   0.207496  0.052882  0.136029  0.054837  0.258047  0.061146  0.027045   \n\n           F         K         M         S  \nSS  0.763723  0.141746  0.571720  0.207496  \nA   0.370670  0.039448  0.274021  0.052882  \nG   0.295909  0.012660  0.134572  0.136029  \nO   0.539708  0.041626  0.722016  0.054837  \nT   0.375067  0.157547  0.137071  0.258047  \nV   0.438281  0.119935  0.163090  0.061146  \nC   0.202182  0.211111  0.039847  0.027045  \nF   1.000000  0.043313  0.522427  0.171674  \nK   0.043313  1.000000  0.074283  0.010853  \nM   0.522427  0.074283  1.000000  0.027996  \nS   0.171674  0.010853  0.027996  1.000000  \n\n\n\n\n\n\n\n\n\nThe strongest associations are SS–F (0.76), O–M (0.72), T–C (0.64), and SS–T (0.63), showing that combined sexually selected traits strongly co-occur with female choice, and olfactory traits with male choice. Visual (V), tactile (T), and male–male competition (C) also form a moderately correlated cluster, while weaker links (e.g., K and S) indicate that female–female competition and intersexual conflict occur largely independently of other traits\n\n\nCode\n# plots – trait prevalence, phylum distribution, histograms (binary will show as 0/1 counts)\n\n#prevalence of binary traits\nif traits_present:\n    prev = df1[traits_present].mean().sort_values(ascending=False)\n    plt.figure(figsize=(10,4))\n    plt.bar(prev.index, prev.values)\n    plt.title(\"Trait prevalence (proportion present)\")\n    plt.ylabel(\"Prevalence\")\n    plt.xlabel(\"Traits\")\n    plt.xticks(rotation=45, ha='right')\n    plt.show()\n\n#phylum distribution\nif target_col:\n    counts = df1[target_col].value_counts()\n    plt.figure(figsize=(12,4))\n    plt.bar(counts.index, counts.values)\n    plt.title(f\"{target_col} distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlabel(\"Phylum Name\")\n    plt.xticks(rotation=90)\n    plt.show()\n\nbinary_cols = [c for c in traits_present if c in df1.columns]\n\n# histograms for binary traits (0/1 only)\nif binary_cols:\n    n = len(binary_cols)\n    ncols = min(5, n)\n    nrows = (n + ncols - 1) // ncols\n    fig, axes = plt.subplots(\n        nrows=nrows, ncols=ncols,\n        figsize=(2.5*ncols, 2*nrows)  # shrink each plot\n    )\n    axes = np.array(axes).reshape(-1) if isinstance(axes, np.ndarray) else [axes]\n\n    for i, col in enumerate(binary_cols):\n        ax = axes[i]\n        ax.hist(df1[col].dropna(), bins=[-0.5, 0.5, 1.5], edgecolor=\"black\")\n        ax.set_title(col, fontsize=9)  # smaller title font\n        ax.set_xticks([0, 1])\n        ax.set_xlabel(\"Binary\", fontsize=8)\n        ax.set_ylabel(\"Count\", fontsize=8)\n\n    for ax in axes[n:]:\n        ax.axis('off')\n\n    plt.tight_layout(pad=1.0)  # tighter spacing\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# traits by phylum (prevalence), if target exists\nif target_col and traits_present:\n    group_prev = df1.groupby(target_col)[traits_present].mean().sort_index()\n    print(\"\\nTrait prevalence by phylum (proportion present):\\n\", group_prev.round(3))\n\n    #barplot per trait aggregated (wide)\n    ax = group_prev.plot(kind='bar', figsize=(12, max(4, 0.35*len(group_prev.columns))))\n    ax.set_title(f\"Trait prevalence by {target_col}\")\n    ax.set_ylabel(\"Prevalence\")\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.show()\n\n\n\nTrait prevalence by phylum (proportion present):\n                      SS      A      G      O      T      V      C     F  \\\nPhylum                                                                    \nAcoela            0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nAnnelida          0.500  0.000  0.000  0.500  0.500  0.000  0.250  0.25   \nArthropoda        0.296  0.037  0.025  0.115  0.149  0.098  0.115  0.20   \nBrachiopoda       0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nBryozoa           0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nChaetognatha      0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nChordata          0.346  0.135  0.000  0.077  0.077  0.212  0.231  0.25   \nCnidaria          0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nCtenophora        0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nEchinodermata     0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nEntoprocta        0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nGastrotricha      0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nGnathostomulida   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nHemichordata      0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nKinorhyncha       0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nMollusca          0.014  0.000  0.000  0.000  0.000  0.014  0.014  0.00   \nNematoda          0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nNematomorpha      0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nNemertea          0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nOnychophora       0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nPhoronida         0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nPlacozoa          0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nPlatyhelminthes   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nPorifera          0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nPriapulida        0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nRotifera          1.000  0.000  0.000  1.000  0.000  0.000  0.000  0.00   \nSipuncula         0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nTardigrada        0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \nXenoturbellida    0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.00   \n\n                      K      M      S  \nPhylum                                 \nAcoela            0.000  0.000  0.000  \nAnnelida          0.250  0.250  0.000  \nArthropoda        0.007  0.122  0.019  \nBrachiopoda       0.000  0.000  0.000  \nBryozoa           0.000  0.000  0.000  \nChaetognatha      0.000  0.000  0.000  \nChordata          0.019  0.058  0.000  \nCnidaria          0.000  0.000  0.000  \nCtenophora        0.000  0.000  0.000  \nEchinodermata     0.000  0.000  0.000  \nEntoprocta        0.000  0.000  0.000  \nGastrotricha      0.000  0.000  0.000  \nGnathostomulida   0.000  0.000  0.000  \nHemichordata      0.000  0.000  0.000  \nKinorhyncha       0.000  0.000  0.000  \nMollusca          0.000  0.000  0.000  \nNematoda          0.000  0.000  0.000  \nNematomorpha      0.000  0.000  0.000  \nNemertea          0.000  0.000  0.000  \nOnychophora       0.000  0.000  0.000  \nPhoronida         0.000  0.000  0.000  \nPlacozoa          0.000  0.000  0.000  \nPlatyhelminthes   0.000  0.000  0.000  \nPorifera          0.000  0.000  0.000  \nPriapulida        0.000  0.000  0.000  \nRotifera          0.000  1.000  0.000  \nSipuncula         0.000  0.000  0.000  \nTardigrada        0.000  0.000  0.000  \nXenoturbellida    0.000  0.000  0.000  \n\n\n\n\n\n\n\n\n\n\n\nCode\n#trait prevalence by phylum\ngroup_prev = df1.groupby(\"Phylum\")[['SS','A','G','O','T','V','C','F','K','M','S']].mean()\n\n#filter to only show phylum × traits where prevalence &gt; 0\nfiltered_prev = group_prev[group_prev &gt; 0].dropna(how=\"all\")\n\nprint(\"Non-zero trait prevalence by phylum (df1):\\n\")\nprint(filtered_prev)\n\n\nNon-zero trait prevalence by phylum (df1):\n\n                   SS         A         G         O         T         V  \\\nPhylum                                                                    \nAnnelida     0.500000       NaN       NaN  0.500000  0.500000       NaN   \nArthropoda   0.295529  0.037077  0.025082  0.114504  0.149400  0.098146   \nChordata     0.346154  0.134615       NaN  0.076923  0.076923  0.211538   \nMollusca     0.014286       NaN       NaN       NaN       NaN  0.014286   \nRotifera     1.000000       NaN       NaN  1.000000       NaN       NaN   \n\n                    C         F         K         M         S  \nPhylum                                                         \nAnnelida     0.250000  0.250000  0.250000  0.250000       NaN  \nArthropoda   0.114504  0.199564  0.006543  0.122137  0.018539  \nChordata     0.230769  0.250000  0.019231  0.057692       NaN  \nMollusca     0.014286       NaN       NaN       NaN       NaN  \nRotifera          NaN       NaN       NaN  1.000000       NaN  \n\n\nTrait prevalence (first plot): - The most common trait is SS (any sexually selected trait, ~27%), followed by F (female choice, ~18%) and T (tactile, ~13%), while traits like K (female–female competition), S (intersexual conflict), and G (gustatory) are rare (&lt;3%).\nPhylum distribution (second plot): - The dataset is highly imbalanced, with Arthropoda dominating (~84%), while Mollusca and Chordata make up smaller fractions, and most other phyla have very few samples.\nTrait binary presence (third plot): - All traits are binary with strong skew toward 0 (absence), confirming sparsity and explaining the high skewness/kurtosis values.\nTrait prevalence by phylum (fourth plot): - Certain phyla (e.g., Arthropoda, Chordata, Annelida) show meaningful diversity of trait presence, while most phyla exhibit almost no sexually selected traits in the dataset.\n\n\nEvolution EDA Assessments\n\n\nCode\n#making a copy of evolution_df\ndf2 = evolution_df.copy()\n\n# quick overview\nprint(f\"\\n=== df2 EDA (evolution_df) ===\")\nprint(f\"Shape: {df2.shape[0]} rows × {df2.shape[1]} columns\")\nprint(\"\\nColumns:\", list(df2.columns))\nprint(\"\\nDtypes:\\n\", df2.dtypes)\n\n# target and trait columns\nall_traits = ['A','G','O','T','V','C','F','K','M','S']  # continuous traits\ntraits_present = [c for c in all_traits if c in df2.columns]\ntarget_col = 'Phylum' if 'Phylum' in df2.columns else None\nid_cols = [c for c in ['Tree'] if c in df2.columns]\n\n#printed shapes below\nprint(\"\\nTarget column:\", target_col)\nprint(\"Trait columns:\", traits_present)\nprint(\"ID columns:\", id_cols)\n\n\n\n=== df2 EDA (evolution_df) ===\nShape: 84 rows × 12 columns\n\nColumns: ['Tree', 'Phylum', 'A', 'G', 'O', 'T', 'V', 'C', 'F', 'K', 'M', 'S']\n\nDtypes:\n Tree        int64\nPhylum     object\nA         float64\nG         float64\nO         float64\nT         float64\nV         float64\nC         float64\nF         float64\nK         float64\nM         float64\nS         float64\ndtype: object\n\nTarget column: Phylum\nTrait columns: ['A', 'G', 'O', 'T', 'V', 'C', 'F', 'K', 'M', 'S']\nID columns: ['Tree']\n\n\nThe evolution_df dataset (84 rows × 12 columns) tracks evolutionary origin rates of 10 sexually selected traits (A–S) across phyla, providing continuous rate-based predictors rather than the binary presence/absence data of family_df.\n\n\nCode\n# numeric & categorical summaries\nnumeric_df = df2.select_dtypes(include='number')\ncat_df = df2.select_dtypes(include=['object','category'])\n\nif not numeric_df.empty:\n    print(\"\\nSummary (numeric):\\n\", numeric_df.describe().T)\nelse:\n    print(\"\\nNo numeric columns for numeric summary.\")\n\nif not cat_df.empty:\n    print(\"\\nSummary (categorical):\\n\", cat_df.describe().T)\nelse:\n    print(\"\\nNo categorical columns for categorical summary.\")\n\n\n\nSummary (numeric):\n       count      mean       std  min  25%  50%  75%       max\nTree   84.0  2.000000  0.821401  1.0  1.0  2.0  3.0  3.000000\nA      84.0  0.000019  0.000069  0.0  0.0  0.0  0.0  0.000301\nG      84.0  0.000063  0.000528  0.0  0.0  0.0  0.0  0.004833\nO      84.0  0.000028  0.000100  0.0  0.0  0.0  0.0  0.000400\nT      84.0  0.000056  0.000230  0.0  0.0  0.0  0.0  0.001200\nV      84.0  0.000117  0.000456  0.0  0.0  0.0  0.0  0.002300\nC      84.0  0.000066  0.000234  0.0  0.0  0.0  0.0  0.001000\nF      84.0  0.000089  0.000323  0.0  0.0  0.0  0.0  0.001341\nK      84.0  0.000005  0.000018  0.0  0.0  0.0  0.0  0.000088\nM      84.0  0.000028  0.000106  0.0  0.0  0.0  0.0  0.000509\nS      84.0  0.000004  0.000020  0.0  0.0  0.0  0.0  0.000108\n\nSummary (categorical):\n        count unique         top freq\nPhylum    84     28  Tardigrada    3\n\n\nThe evolution_df traits have extremely small mean rates (mostly near 0 with rare spikes), showing that sexually selected traits originate very infrequently across lineages; meanwhile, the categorical data span 28 phyla with a relatively even spread (max frequency only 3 for Tardigrada), making this dataset far more balanced than family_df (confirmed in the phylum distribution plot below)\n\n\nCode\n# missing values\nna = df2.isna().sum()\nna = na[na &gt; 0]\nif na.empty:\n    print(\"\\nNo missing values detected.\")\nelse:\n    print(\"\\nColumns with nulls:\\n\", na)\n    print(\"\\nNull %:\\n\", (na/len(df2)*100).round(2))\n\n\n\nNo missing values detected.\n\n\n\n\nCode\n# unique counts\nprint(\"\\nUnique values per column:\\n\", df2.nunique())\n\n\n\nUnique values per column:\n Tree       3\nPhylum    28\nA          6\nG          3\nO          5\nT          6\nV          5\nC          6\nF          6\nK          5\nM          6\nS          4\ndtype: int64\n\n\nEach trait in evolution_df only has a few unique rate values (mostly 3–6), so even though they’re stored as continuous numbers, the values are very small and clustered. The dataset still covers 28 phyla, giving it wide taxonomic coverage but not much variation within each trait.\n\n\nCode\n#outlier scan (IQR) – continuous traits only\nprint(\"\\nOutlier scan (IQR):\")\nfor col in numeric_df.columns:\n    if col in id_cols:  # skip ID\n        print(f\"{col}: skipped (ID)\")\n        continue\n    Q1 = df2[col].quantile(0.25)\n    Q3 = df2[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lo = Q1 - 1.5*IQR\n    hi = Q3 + 1.5*IQR\n    mask = (df2[col] &lt; lo) | (df2[col] &gt; hi) #mark values below or above IQR method for detecting outliers above\n    cnt = int(mask.sum()) #counts these values\n    pct = 100*cnt/len(df2) #percentage of outliers\n    print(f\"{col}: {cnt} outliers ({pct:.2f}%)\") \n\n\n\nOutlier scan (IQR):\nTree: skipped (ID)\nA: 6 outliers (7.14%)\nG: 3 outliers (3.57%)\nO: 6 outliers (7.14%)\nT: 6 outliers (7.14%)\nV: 9 outliers (10.71%)\nC: 9 outliers (10.71%)\nF: 6 outliers (7.14%)\nK: 6 outliers (7.14%)\nM: 6 outliers (7.14%)\nS: 3 outliers (3.57%)\n\n\nfollows up with the outlier details below:\n\n\nCode\n#traits to scan (exclude ID/target)\ntrait_cols = [c for c in df2.columns if c not in [\"Tree\", \"Phylum\"]]\n\n#IQR outlier finder (returns both high and low outliers)\ndef find_outliers_iqr(d, col):\n    q1 = d[col].quantile(0.25)\n    q3 = d[col].quantile(0.75)\n    iqr = q3 - q1\n    lower = q1 - 1.5 * iqr\n    upper = q3 + 1.5 * iqr\n    out = d[(d[col] &lt; lower) | (d[col] &gt; upper)].copy()\n    out[\"OutlierSide\"] = out[col].apply(lambda x: \"low\" if x &lt; lower else \"high\")\n    out[\"Trait\"] = col\n    return out[[\"Trait\", \"Phylum\", col, \"OutlierSide\"]].rename(columns={col: \"Value\"})\n\n#dict of DataFrames per trait\noutlier_dict = {col: find_outliers_iqr(df2, col) for col in trait_cols}\n\n#tidy table of all outliers (stacked)\noutliers_tidy = pd.concat(outlier_dict.values(), ignore_index=True)\n\n#counts by trait\noutlier_counts_by_trait = (\n    outliers_tidy.groupby(\"Trait\", as_index=False)\n    .size()\n    .rename(columns={\"size\": \"n_outliers\"})\n    .sort_values(\"n_outliers\", ascending=False)\n)\n\n#phyla contributing outliers per trait\nphyla_per_trait = (\n    outliers_tidy.groupby(\"Trait\")[\"Phylum\"]\n    .apply(lambda s: \", \".join(sorted(s.unique())))\n    .reset_index(name=\"Phyla_with_outliers\")\n)\n\n#combined into one summary\noutlier_summary = outlier_counts_by_trait.merge(phyla_per_trait, on=\"Trait\", how=\"left\")\n\nprint(\"Outlier summary (IQR):\")\nprint(outlier_summary.to_string(index=False))\n\n\nOutlier summary (IQR):\nTrait  n_outliers            Phyla_with_outliers\n    C           9 Arthropoda, Chordata, Mollusca\n    V           9 Arthropoda, Chordata, Mollusca\n    A           6           Arthropoda, Chordata\n    F           6           Arthropoda, Chordata\n    K           6           Arthropoda, Chordata\n    M           6           Arthropoda, Chordata\n    O           6           Arthropoda, Chordata\n    T           6           Arthropoda, Chordata\n    G           3                     Arthropoda\n    S           3                     Arthropoda\n\n\nOutliers in trait evolution rates are almost entirely concentrated in Arthropoda and Chordata, with Mollusca contributing only for Visual and Male–male competition, while all other phyla show none. It suggests sexually selected traits are usually found in Arthropoda, Chordata, and a bit of Mollusca. Unfortunately, evolution rates are pretty imbalanced here as well.\n\n\nCode\n# Skewness\nif not numeric_df.empty:\n    with np.errstate(all='ignore'):\n        skew_vals = numeric_df.drop(columns=id_cols, errors='ignore').skew(numeric_only=True)\n\n        print(\"\\n=== Skewness ===\")\n        for col, val in skew_vals.items():\n            print(f\"{col:5s}: {val: .4f}\")\nelse:\n    print(\"\\nNo numeric columns for skewness.\")\n\n# Kurtosis\nif not numeric_df.empty:\n    with np.errstate(all='ignore'):\n        kurt_vals = numeric_df.drop(columns=id_cols, errors='ignore').kurt(numeric_only=True)\n\n        print(\"\\n=== Kurtosis ===\")\n        for col, val in kurt_vals.items():\n            print(f\"{col:5s}: {val: .4f}\")\nelse:\n    print(\"\\nNo numeric columns for kurtosis.\")\n\n\n\n=== Skewness ===\nA    :  3.5053\nG    :  9.0968\nO    :  3.3938\nT    :  4.4907\nV    :  4.2405\nC    :  3.4515\nF    :  3.4248\nK    :  4.0070\nM    :  3.8618\nS    :  5.0951\n\n=== Kurtosis ===\nA    :  10.8319\nG    :  83.1277\nO    :  9.7628\nT    :  19.7685\nV    :  17.6104\nC    :  10.3801\nF    :  10.0587\nK    :  15.5086\nM    :  14.1807\nS    :  24.5445\n\n\nAll trait origin rates are strongly right-skewed with high kurtosis, meaning most values sit near zero while a few phyla show much higher rates. The most extreme cases are Gustatory (G) and Intersexual conflict (S), which are both very rare and unevenly distributed. The least skewed are Olfactory (O, ~3.39) and Female choice (F, ~3.42), but even these remain heavily tilted to the right rather than balanced.\n\n\nCode\n#correlations\ncont_cols = [c for c in traits_present if c in df2.columns]\nif cont_cols:\n    corr = df2[cont_cols].corr().abs()\n    print(\"\\nCorrelation matrix (|r|):\\n\", corr.round(3))\n\n    # Heatmap\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(\n        corr,\n        annot=True,\n        cmap=\"coolwarm\",\n        fmt=\".2f\",\n        linewidths=0.5,\n        cbar_kws={\"shrink\": 0.8, \"label\": \"|r|\"}\n    )\n    plt.title(\"Absolute Correlation Matrix — Evolution Traits\", fontsize=14, pad=12)\n    plt.xticks(rotation=45, ha=\"right\")\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No continuous trait columns found in df2.\")\n\n\n\nCorrelation matrix (|r|):\n        A      G      O      T      V      C      F      K      M      S\nA  1.000  0.365  0.990  0.805  0.962  0.967  0.998  0.980  0.906  0.585\nG  0.365  1.000  0.450  0.603  0.209  0.484  0.383  0.257  0.542  0.628\nO  0.990  0.450  1.000  0.879  0.915  0.992  0.996  0.942  0.955  0.691\nT  0.805  0.603  0.879  1.000  0.613  0.928  0.842  0.670  0.980  0.952\nV  0.962  0.209  0.915  0.613  1.000  0.862  0.942  0.997  0.756  0.342\nC  0.967  0.484  0.992  0.928  0.862  1.000  0.981  0.896  0.982  0.770\nF  0.998  0.383  0.996  0.842  0.942  0.981  1.000  0.964  0.932  0.638\nK  0.980  0.257  0.942  0.670  0.997  0.896  0.964  1.000  0.802  0.410\nM  0.906  0.542  0.955  0.980  0.756  0.982  0.932  0.802  1.000  0.874\nS  0.585  0.628  0.691  0.952  0.342  0.770  0.638  0.410  0.874  1.000\n\n\n\n\n\n\n\n\n\nThis here, is interesting. Most sexually selected traits in evolution_df are almost perfectly correlated, possibly forming a tight co-evolving cluster (auditory, olfactory, visual, competition, and choice traits). The only exception is gustatory (G), which shows weaker links and stands out as the most independent trait.\n\n\nCode\n# plots – histograms, phylum distribution, presence prevalence\n\n#phylum distribution\nif target_col:\n    counts = df2[target_col].value_counts()\n    plt.figure(figsize=(10,4))\n    plt.bar(counts.index, counts.values)\n    plt.title(f\"{target_col} distribution\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=90)\n    plt.show()\n\n#presence prevalence derived from rates (&gt;0)\nif cont_cols:\n    presence = (df2[cont_cols] &gt; 0).mean().sort_values(ascending=False)\n    plt.figure(figsize=(10,4))\n    plt.bar(presence.index, presence.values)\n    plt.title(\"Presence prevalence from rates (&gt;0)\")\n    plt.ylabel(\"Prevalence (mean)\")\n    plt.xlabel(\"Traits\")\n    plt.xticks(rotation=45, ha='right')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n#trait means by phylum\nif target_col and cont_cols:\n    means_by_phylum = df2.groupby(target_col)[cont_cols].mean().sort_index()\n    print(\"\\nTrait means by phylum:\\n\", means_by_phylum.round(3))\n\n    ax = means_by_phylum.plot(kind='bar', figsize=(12, max(4, 0.35*len(means_by_phylum.columns))))\n    ax.set_title(f\"Trait means by {target_col}\")\n    ax.set_ylabel(\"Mean rate\")\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.show()\n\n\n\nTrait means by phylum:\n                    A      G    O      T      V      C      F    K      M    S\nPhylum                                                                       \nAcoela           0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nAnnelida         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nArthropoda       0.0  0.002  0.0  0.001  0.001  0.001  0.001  0.0  0.001  0.0\nBrachiopoda      0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nBryozoa          0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nChaetognatha     0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nChordata         0.0  0.000  0.0  0.000  0.002  0.001  0.001  0.0  0.000  0.0\nCnidaria         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nCtenophora       0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nEchinodermata    0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nEntoprocta       0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nGastrotricha     0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nGnathostomulida  0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nHemichordata     0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nKinorhynca       0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nMollusca         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nNematoda         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nNematomorpha     0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nNemertea         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nOnychophora      0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nPhoronida        0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nPlacozoa         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nPlatyhelminthes  0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nPorifera         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nPriapulida       0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nRotifera         0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nTardigrada       0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\nXenoturbellida   0.0  0.000  0.0  0.000  0.000  0.000  0.000  0.0  0.000  0.0\n\n\n\n\n\n\n\n\n\n\n\nCode\n#filter df2 trait means by phylum to only show &gt; 0 values\ntrait_means = df2.groupby(\"Phylum\")[['A','G','O','T','V','C','F','K','M','S']].mean()\nfiltered = trait_means[trait_means &gt; 0].dropna(how=\"all\")\n\nprint(\"Non-zero trait means by phylum:\\n\")\nprint(filtered)\n\n\nNon-zero trait means by phylum:\n\n                   A         G         O         T         V         C  \\\nPhylum                                                                   \nArthropoda  0.000227  0.001774  0.000384  0.001187  0.000923  0.000997   \nChordata    0.000299       NaN  0.000387  0.000377  0.002300  0.000800   \nMollusca         NaN       NaN       NaN       NaN  0.000059  0.000059   \n\n                   F         K         M         S  \nPhylum                                              \nArthropoda  0.001152  0.000043  0.000506  0.000108  \nChordata    0.001333  0.000087  0.000276       NaN  \nMollusca         NaN       NaN       NaN       NaN  \n\n\nPhylum distribution (first plot): - All phyla are evenly represented (3 each) which means the class representation is balanced.\nTrait prevalence (second plot): - The most common evolving traits are Visual (V) and Male–male competition (C), whereas Gustatory (G) and Intersexual conflict (S) are the rarest\nTraits by phylum (third plot): - This third plot confirms the imbalanced evolutionary rates across phyla where a lot of detected sexually selected traits are usually found in Arthropoda, Chordata, and a bit of Mollusca.\n\n\nSummarized Key Insights\nFamily - Dataset structure: The dataset has 1,087 rows × 13 columns, with Phylum as the categorical target, 11 binary-coded sexually selected traits (SS–S) as predictors, and Tree_Label as a unique ID. - Severe class imbalance: The Arthropoda phylum dominates (~84%), while Mollusca (~8%) and Chordata (~5%) are minor classes, and most other phyla have only a handful of samples. This imbalance will strongly affect classification performance. - Trait prevalence patterns: Most traits are rare, with SS (any sexually selected trait, ~27%) and F (female choice, ~18%) being the most frequent. In contrast, K (female–female competition), S (intersexual conflict), and G (gustatory) appear in &lt;3% of samples, meaning they contribute very sparse signals. - Distribution shape: Because traits are binary and sparse, they show strong positive skew and extreme kurtosis, indicating most samples lack a given trait. This makes the dataset sparse and unbalanced at both feature and target levels. - Correlation structure: Traits cluster into co-occurring groups: - SS and F are very tightly linked (r ≈ 0.76), - Olfactory (O) and Male choice (M) also correlate strongly (r ≈ 0.72), - Tactile (T) and Male–male competition (C) pair closely (r ≈ 0.64). - These clusters suggest certain evolutionary mechanisms tend to evolve together. - By phylum trait diversity: Only a few phyla (Arthropoda, Chordata, Annelida) show meaningful variation in sexually selected traits. However, most other phyla have near-zero prevalence, meaning trait-driven classification will be heavily biased toward the larger groups.\nEvolution - Dataset structure: 84 rows × 12 columns; 10 continuous trait rate columns (A–S), Phylum as target, Tree as ID. - Class balance: 28 phyla, each appearing exactly 3 times → perfectly balanced distribution. - Trait distributions: All traits are heavily right-skewed with high kurtosis, clustered near zero with only a few high values. - Outliers: Concentrated almost entirely in Arthropoda and Chordata, with Mollusca contributing for Visual (V) and Male–male competition (C). - Trait prevalence (nonzero rates): Most common are Visual (V) and Male–male competition (C) (~11%), while Gustatory (G) and Intersexual conflict (S) are the rarest (~4%). [“Presence prevalence from rates (&gt;0 → 1)” bar chart] - Correlations: Nearly all traits co-evolve in a tight cluster (correlations &gt;0.95), with Gustatory (G) standing out as the least connected trait.\nFamily_df shows which traits are present or absent but is heavily skewed toward Arthropoda, while Evolution_df tracks how likely traits evolve across phyla, with a balanced sample, although traits are not balanced and strongly co-correlated together.\n\n\n\n\nData Preprocessing (Preparations for ML)\n\nFamily Preprocessing\nI made a copy of family_df known as family_preprocessing\n\n\nCode\n# Make a copy for preprocessing steps\nfamily_preprocessing = family_df.copy()\n\n# Drop ID column (Tree_Label)\nif \"Tree_Label\" in family_preprocessing.columns:\n    family_preprocessing = family_preprocessing.drop(columns=[\"Tree_Label\"])\n\nfamily_preprocessing.head()\n\n\n\n\n\n\n\n\n\nPhylum\nSS\nA\nG\nO\nT\nV\nC\nF\nK\nM\nS\n\n\n\n\n0\nMollusca\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\nMollusca\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\nChordata\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\nChordata\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\nChordata\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\nI won’t be using tree_label in the modeling\n\n\nCode\n#strip leading/trailing spaces in Phylum column\nfamily_preprocessing[\"Phylum\"] = family_preprocessing[\"Phylum\"].astype(str).str.strip()\n\n#defined superphylum groupings (after some research)\ngroups = {\n    \"Ecdysozoa\": {\n        \"Arthropoda\", \"Nematoda\", \"Nematomorpha\", \"Priapulida\",\n        \"Kinorhyncha\", \"Kinorhynca\", \"Tardigrada\", \"Onychophora\"\n    },\n    \"Lophotrochozoa\": {\n        \"Mollusca\", \"Annelida\", \"Brachiopoda\", \"Bryozoa\",\n        \"Phoronida\", \"Nemertea\", \"Rotifera\", \"Gastrotricha\",\n        \"Gnathostomulida\", \"Sipuncula\", \"Platyhelminthes\", \"Entoprocta\"\n    },\n    \"Deuterostomia\": {\n        \"Chordata\", \"Echinodermata\", \"Hemichordata\"\n    },\n    \"Basal Metazoa & Non-Bilaterians\": {\n        \"Porifera\", \"Placozoa\", \"Cnidaria\", \"Ctenophora\"\n    },\n    \"Basal Bilateria\": {\n        \"Acoela\", \"Chaetognatha\", \"Xenoturbellida\"\n    }\n}\n\n#mapping dictionary\nphylum_to_group = {}\nfor group_name, phyla in groups.items():\n    for p in phyla:\n        phylum_to_group[p] = group_name\n\n#addedSuperphylum column\nfamily_preprocessing[\"Superphylum\"] = family_preprocessing[\"Phylum\"].map(phylum_to_group)\n\n# Coverage check\nunique_phyla = set(family_preprocessing[\"Phylum\"].unique())\nassigned = [p for p in unique_phyla if p in phylum_to_group]\nunassigned = [p for p in unique_phyla if p not in phylum_to_group]\n\ndf_map = pd.DataFrame({\n    \"Phylum\": sorted(unique_phyla),\n    \"Assigned_Group\": [phylum_to_group.get(p, \"\") for p in sorted(unique_phyla)],\n    \"Is_Assigned\": [p in phylum_to_group for p in sorted(unique_phyla)]\n})\n\n#header\nprint(family_preprocessing.head())\n\n\n     Phylum  SS  A  G  O  T  V  C  F  K  M  S     Superphylum\n0  Mollusca   0  0  0  0  0  0  0  0  0  0  0  Lophotrochozoa\n1  Mollusca   0  0  0  0  0  0  0  0  0  0  0  Lophotrochozoa\n2  Chordata   0  0  0  0  0  0  0  0  0  0  0   Deuterostomia\n3  Chordata   0  0  0  0  0  0  0  0  0  0  0   Deuterostomia\n4  Chordata   0  0  0  0  0  0  0  0  0  0  0   Deuterostomia\n\n\nNow I can encode superphylum and will not be including phylum to avoid redundancy\n\n\nCode\n# encode Superphylum target\nsup_le = LabelEncoder()\nfamily_preprocessing[\"Superphylum_encoded\"] = sup_le.fit_transform(\n    family_preprocessing[\"Superphylum\"].astype(str)\n)\n\n# features = trait flags only (exclude Superphylum columns)\ntrait_cols = [\"SS\",\"A\",\"G\",\"O\",\"T\",\"V\",\"C\",\"F\",\"K\",\"M\",\"S\"]\nX = family_preprocessing[trait_cols].copy()\ny = family_preprocessing[\"Superphylum_encoded\"].copy()\n\nprint(\"Classes:\", dict(enumerate(sup_le.classes_)))\n\n\nClasses: {0: 'Basal Bilateria', 1: 'Basal Metazoa & Non-Bilaterians', 2: 'Deuterostomia', 3: 'Ecdysozoa', 4: 'Lophotrochozoa'}\n\n\nAs you may note, family have extremely unbalanced class representations, so I added class weights to aid with balanced classes for model predictions\n\n\nCode\n#train/test split\nX_train_fam, X_test_fam, y_train_fam, y_test_fam = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n#class weights\nclasses = np.unique(y_train_fam)\nclass_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train_fam)\ncw_fam = {c: w for c, w in zip(classes, class_weights)}\n\n#standardize features below\nscaler_fam = StandardScaler()\nX_train_fam_scaled = scaler_fam.fit_transform(X_train_fam)\nX_test_fam_scaled  = scaler_fam.transform(X_test_fam)\n\nprint(\"Train/Test:\", X_train_fam.shape, X_test_fam.shape)\nprint(\"Class weights:\", cw_fam)\n\n#after preprocessing, making a copy of the preprocessed data -&gt; family_ML for model evaluations\nfamily_ML = family_preprocessing.copy()\n\n\nTrain/Test: (869, 11) (218, 11)\nClass weights: {np.int64(0): np.float64(57.93333333333333), np.int64(1): np.float64(19.31111111111111), np.int64(2): np.float64(3.697872340425532), np.int64(3): np.float64(0.23423180592991913), np.int64(4): np.float64(2.5558823529411763)}\n\n\n\n\nEvolution Preprocessing\nI made a copy of evolution_df named evolution_preprocessing here\n\n\nCode\n#making a copy for preprocessing steps\nevolution_preprocessing = evolution_df.copy()\n\n#Drop ID column (Tree_label)\nif \"Tree\" in evolution_preprocessing.columns:\n    evolution_preprocessing = evolution_preprocessing.drop(columns=[\"Tree\"])\n\nevolution_preprocessing.head()\n\n\n\n\n\n\n\n\n\nPhylum\nA\nG\nO\nT\nV\nC\nF\nK\nM\nS\n\n\n\n\n0\nTardigrada\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n1\nOnychophora\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\nArthropoda\n0.000228\n0.000244\n0.000376\n0.00118\n0.000935\n0.000995\n0.001178\n0.000043\n0.000509\n0.000108\n\n\n3\nNematoda\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n4\nNematomorpha\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\nCode\n#stripped whitespace from Phylum names\nevolution_preprocessing[\"Phylum\"] = evolution_preprocessing[\"Phylum\"].astype(str).str.strip()\n\n#defined superphylum groupings\ngroups = {\n    \"Ecdysozoa\": {\n        \"Arthropoda\", \"Nematoda\", \"Nematomorpha\", \"Priapulida\",\n        \"Kinorhyncha\", \"Kinorhynca\", \"Tardigrada\", \"Onychophora\"\n    },\n    \"Lophotrochozoa\": {\n        \"Mollusca\", \"Annelida\", \"Brachiopoda\", \"Bryozoa\",\n        \"Phoronida\", \"Nemertea\", \"Rotifera\", \"Gastrotricha\",\n        \"Gnathostomulida\", \"Sipuncula\", \"Platyhelminthes\", \"Entoprocta\"\n    },\n    \"Deuterostomia\": {\n        \"Chordata\", \"Echinodermata\", \"Hemichordata\"\n    },\n    \"Basal Metazoa & Non-Bilaterians\": {\n        \"Porifera\", \"Placozoa\", \"Cnidaria\", \"Ctenophora\"\n    },\n    \"Basal Bilateria\": {\n        \"Acoela\", \"Chaetognatha\", \"Xenoturbellida\"\n    }\n}\n\n#mapping dictionary\nphylum_to_group = {}\nfor group_name, phyla in groups.items():\n    for p in phyla:\n        phylum_to_group[p] = group_name\n\n#added Superphylum column\nevolution_preprocessing[\"Superphylum\"] = evolution_preprocessing[\"Phylum\"].map(phylum_to_group)\n\n#verify coverage below\nunique_phyla = set(evolution_preprocessing[\"Phylum\"].unique())\nunassigned = [p for p in unique_phyla if p not in phylum_to_group]\n\nprint(\"Total unique phyla:\", len(unique_phyla))\nprint(\"Unassigned phyla (should be empty):\", unassigned)\nevolution_preprocessing.head()\n\n\nTotal unique phyla: 28\nUnassigned phyla (should be empty): []\n\n\n\n\n\n\n\n\n\nPhylum\nA\nG\nO\nT\nV\nC\nF\nK\nM\nS\nSuperphylum\n\n\n\n\n0\nTardigrada\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\nEcdysozoa\n\n\n1\nOnychophora\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\nEcdysozoa\n\n\n2\nArthropoda\n0.000228\n0.000244\n0.000376\n0.00118\n0.000935\n0.000995\n0.001178\n0.000043\n0.000509\n0.000108\nEcdysozoa\n\n\n3\nNematoda\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\nEcdysozoa\n\n\n4\nNematomorpha\n0.000000\n0.000000\n0.000000\n0.00000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\nEcdysozoa\n\n\n\n\n\n\n\nIt shows that I was able to group literally all phyla correctly into superphyla groups leaving nothing unassigned, so it should work for family as well\n\n\nCode\n#encoding superphylum:\n#encode Superphylum into numeric labels, keep the text column\nencoder = LabelEncoder()\nevolution_preprocessing[\"Superphylum_encoded\"] = encoder.fit_transform(\n    evolution_preprocessing[\"Superphylum\"].astype(str)\n)\n\n#mapping for reference\nsuperphylum_classes = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\nprint(\"Superphylum encoding mapping:\", superphylum_classes)\n\nevolution_preprocessing[[\"Phylum\", \"Superphylum\", \"Superphylum_encoded\"]].head()\n\n\nSuperphylum encoding mapping: {'Basal Bilateria': np.int64(0), 'Basal Metazoa & Non-Bilaterians': np.int64(1), 'Deuterostomia': np.int64(2), 'Ecdysozoa': np.int64(3), 'Lophotrochozoa': np.int64(4)}\n\n\n\n\n\n\n\n\n\nPhylum\nSuperphylum\nSuperphylum_encoded\n\n\n\n\n0\nTardigrada\nEcdysozoa\n3\n\n\n1\nOnychophora\nEcdysozoa\n3\n\n\n2\nArthropoda\nEcdysozoa\n3\n\n\n3\nNematoda\nEcdysozoa\n3\n\n\n4\nNematomorpha\nEcdysozoa\n3\n\n\n\n\n\n\n\nI encoded superphylum and intended to use it as a target variable for both family and evolution DF\n\n\nCode\n# encoding and log + scaling \n\n#encode Superphylum (target)\nsuperphylum_le_evo = LabelEncoder()\nevolution_preprocessing[\"Superphylum_encoded\"] = superphylum_le_evo.fit_transform(\n    evolution_preprocessing[\"Superphylum\"].astype(str)\n)\n\n#defined features: \n#continuous rates only (drop phylum target completely)\nrate_cols = [\"A\",\"G\",\"O\",\"T\",\"V\",\"C\",\"F\",\"K\",\"M\",\"S\"]\nX_rates = evolution_preprocessing[rate_cols]\ny_evo = evolution_preprocessing[\"Superphylum_encoded\"]\n\n#Log transform the rates\nX_log = np.log1p(X_rates)\n\n#standardized features below\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_log)\n\n#final features are just scaled rates\nX_evo_final = X_scaled\n\n#one per class in test (stratify on superphyla now)\nX_train_evo, X_test_evo, y_train_evo, y_test_evo = train_test_split(\n    X_evo_final, y_evo,\n    test_size=1/3,     \n    random_state=42,\n    stratify=y_evo\n)\n\n#mapping for decoding predictions later\nsuperphylum_id_to_name_evo = {i: n for i, n in enumerate(superphylum_le_evo.classes_)}\n\nprint(\"Train/Test shapes:\", X_train_evo.shape, X_test_evo.shape)\nprint(\"Unique superphyla:\", len(superphylum_id_to_name_evo))\nprint(\"Example mapping (id -&gt; name):\", list(superphylum_id_to_name_evo.items())[:5])\n\n#evolution_preprocessing copy into evolution_ML\nevolution_ML = evolution_preprocessing.copy()\n\n#header\nprint(evolution_ML.head())\n\n\nTrain/Test shapes: (56, 10) (28, 10)\nUnique superphyla: 5\nExample mapping (id -&gt; name): [(0, 'Basal Bilateria'), (1, 'Basal Metazoa & Non-Bilaterians'), (2, 'Deuterostomia'), (3, 'Ecdysozoa'), (4, 'Lophotrochozoa')]\n         Phylum         A         G         O        T         V         C  \\\n0    Tardigrada  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n1   Onychophora  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n2    Arthropoda  0.000228  0.000244  0.000376  0.00118  0.000935  0.000995   \n3      Nematoda  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n4  Nematomorpha  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n\n          F         K         M         S Superphylum  Superphylum_encoded  \n0  0.000000  0.000000  0.000000  0.000000   Ecdysozoa                    3  \n1  0.000000  0.000000  0.000000  0.000000   Ecdysozoa                    3  \n2  0.001178  0.000043  0.000509  0.000108   Ecdysozoa                    3  \n3  0.000000  0.000000  0.000000  0.000000   Ecdysozoa                    3  \n4  0.000000  0.000000  0.000000  0.000000   Ecdysozoa                    3  \n\n\nThe reason I train split 1/3 instead of 1/2 is due to smaller sample size for evolution with around 84 samples\nNow, I have both family and evolution preprocessed and made copies in case (family_ML and evolution_ML)\n\n\n\n\nModeling Evaluations\n\nFamily Modeling\n\n\nCode\n# =========================================================\n#Family below\n\nRANDOM_STATE = 42  # keep consistent\n\n# Features & Target \ntrait_cols_fam = [\"SS\",\"A\",\"G\",\"O\",\"T\",\"V\",\"C\",\"F\",\"K\",\"M\",\"S\"]  # exclude Superphylum_encoded\nX_fam_all = family_ML[trait_cols_fam].copy()\ny_fam_all = family_ML[\"Superphylum_encoded\"].copy()              # target is Superphylum\n\n# Stratified Split\nX_train_fam, X_test_fam, y_train_fam, y_test_fam = train_test_split(\n    X_fam_all, y_fam_all, test_size=0.2, random_state=RANDOM_STATE, stratify=y_fam_all\n)\n\n# Class Weights (from TRAIN)\nclasses_fam = np.unique(y_train_fam)\nweights_fam = compute_class_weight(\"balanced\", classes=classes_fam, y=y_train_fam)\ncw_fam = {c: w for c, w in zip(classes_fam, weights_fam)}\n\n# Scale for LR only\nscaler_fam = StandardScaler()\nX_train_fam_scaled = scaler_fam.fit_transform(X_train_fam)\nX_test_fam_scaled  = scaler_fam.transform(X_test_fam)\n\n# Models\ndt_fam = DecisionTreeClassifier(\n    random_state=RANDOM_STATE,\n    class_weight=cw_fam,\n    max_depth=8,\n    min_samples_split=4,\n    min_samples_leaf=2\n)\n\nrf_fam = RandomForestClassifier(\n    random_state=RANDOM_STATE,\n    class_weight=\"balanced_subsample\",\n    n_estimators=300,\n    max_depth=12,\n    min_samples_split=4,\n    min_samples_leaf=2,\n    n_jobs=1   #disabled parallelism (repeated warnings)\n)\n\nlr_fam = LogisticRegression(\n    max_iter=2000,\n    random_state=RANDOM_STATE,\n    class_weight=cw_fam,\n    multi_class=\"multinomial\",\n    C=0.5,\n    solver=\"lbfgs\",\n    n_jobs=1\n)\n\n# Train\ndt_fam.fit(X_train_fam, y_train_fam)\nrf_fam.fit(X_train_fam, y_train_fam)\nlr_fam.fit(X_train_fam_scaled, y_train_fam)\n\n# Predictions\ndt_pred_fam = dt_fam.predict(X_test_fam)\nrf_pred_fam = rf_fam.predict(X_test_fam)\nlr_pred_fam = lr_fam.predict(X_test_fam_scaled)\n\n# Evaluation\nprint(\"=== FAMILY (Superphylum) RESULTS ===\")\nlabels_eval = np.unique(y_test_fam)\n\nfor name, pred in [\n    (\"Decision Tree\", dt_pred_fam),\n    (\"Random Forest\", rf_pred_fam),\n    (\"Logistic Regression\", lr_pred_fam),\n]:\n    acc  = accuracy_score(y_test_fam, pred)\n    balc = balanced_accuracy_score(y_test_fam, pred)\n    f1m  = f1_score(y_test_fam, pred, average=\"macro\", labels=labels_eval, zero_division=0)\n    print(f\"\\n{name}: acc={acc:.3f} | bal_acc={balc:.3f} | macro-F1={f1m:.3f}\")\n    print(classification_report(y_test_fam, pred, labels=labels_eval, zero_division=0))\n    print(\"Confusion matrix:\\n\", confusion_matrix(y_test_fam, pred, labels=labels_eval))\n\n# CV on random forest\nmin_count_fam = pd.Series(y_fam_all).value_counts().min()\nif min_count_fam &gt;= 3:\n    n_splits_fam = int(min(5, min_count_fam))\n    cv_folds_fam = StratifiedKFold(n_splits=n_splits_fam, shuffle=True, random_state=RANDOM_STATE)\n    fam_cv_rf = cross_val_score(\n        rf_fam, X_fam_all, y_fam_all, cv=cv_folds_fam, scoring=\"f1_macro\", n_jobs=1  # &lt;-- disable parallelism\n    )\n    print(f\"\\n[FAMILY Superphylum] RF {n_splits_fam}-fold CV macro-F1: {fam_cv_rf.mean():.3f} ± {fam_cv_rf.std():.3f}\")\nelse:\n    print(\"\\n[FAMILY Superphylum] Skipping CV: smallest class &lt; 3 samples.\")\n\n\n=== FAMILY (Superphylum) RESULTS ===\n\nDecision Tree: acc=0.147 | bal_acc=0.280 | macro-F1=0.087\n              precision    recall  f1-score   support\n\n           0       0.01      1.00      0.01         1\n           1       0.00      0.00      0.00         2\n           2       0.12      0.25      0.16        12\n           3       0.93      0.15      0.26       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.15       218\n   macro avg       0.21      0.28      0.09       218\nweighted avg       0.80      0.15      0.23       218\n\nConfusion matrix:\n [[  1   0   0   0   0]\n [  2   0   0   0   0]\n [  8   0   3   1   0]\n [136   0  22  28   0]\n [ 16   0   0   1   0]]\n\nRandom Forest: acc=0.229 | bal_acc=0.283 | macro-F1=0.128\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         1\n           1       0.01      1.00      0.02         2\n           2       0.33      0.17      0.22        12\n           3       0.94      0.25      0.39       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.23       218\n   macro avg       0.26      0.28      0.13       218\nweighted avg       0.82      0.23      0.35       218\n\nConfusion matrix:\n [[  0   1   0   0   0]\n [  0   2   0   0   0]\n [  0   8   2   2   0]\n [  0 136   4  46   0]\n [  0  16   0   1   0]]\n\nLogistic Regression: acc=0.216 | bal_acc=0.296 | macro-F1=0.129\n              precision    recall  f1-score   support\n\n           0       0.01      1.00      0.01         1\n           1       0.00      0.00      0.00         2\n           2       0.27      0.25      0.26        12\n           3       0.98      0.23      0.37       186\n           4       0.00      0.00      0.00        17\n\n    accuracy                           0.22       218\n   macro avg       0.25      0.30      0.13       218\nweighted avg       0.85      0.22      0.33       218\n\nConfusion matrix:\n [[  1   0   0   0   0]\n [  2   0   0   0   0]\n [  8   0   3   1   0]\n [136   0   7  43   0]\n [ 16   0   1   0   0]]\n\n[FAMILY Superphylum] RF 4-fold CV macro-F1: 0.109 ± 0.011\n\n\n\n\nCode\n# =========================================================\n# Summary of FAMILY (Superphylum) Results\n\nprint(\"=== FAMILY (Superphylum) SUMMARY ===\")\n\nprint(\"\\nDecision Tree\")\nprint(\" - Accuracy: 0.147\")\nprint(\" - Balanced Accuracy: 0.280\")\nprint(\" - Macro F1: 0.087\")\nprint(\" - Strong bias toward majority class, poor minority performance.\")\n\nprint(\"\\nRandom Forest\")\nprint(\" - Accuracy: 0.229\")\nprint(\" - Balanced Accuracy: 0.283\")\nprint(\" - Macro F1: 0.128\")\nprint(\" - Slightly better than Decision Tree, but still dominated by majority class.\")\n\nprint(\"\\nLogistic Regression\")\nprint(\" - Accuracy: 0.216\")\nprint(\" - Balanced Accuracy: 0.296\")\nprint(\" - Macro F1: 0.129\")\nprint(\" - Similar to Random Forest, recalls minority class a little better.\")\n\nprint(\"\\nCross-Validation (Random Forest)\")\nprint(\" - 4-fold CV Macro F1: 0.109 ± 0.011\")\nprint(\" - Confirms weak generalization across classes.\")\n\n\n=== FAMILY (Superphylum) SUMMARY ===\n\nDecision Tree\n - Accuracy: 0.147\n - Balanced Accuracy: 0.280\n - Macro F1: 0.087\n - Strong bias toward majority class, poor minority performance.\n\nRandom Forest\n - Accuracy: 0.229\n - Balanced Accuracy: 0.283\n - Macro F1: 0.128\n - Slightly better than Decision Tree, but still dominated by majority class.\n\nLogistic Regression\n - Accuracy: 0.216\n - Balanced Accuracy: 0.296\n - Macro F1: 0.129\n - Similar to Random Forest, recalls minority class a little better.\n\nCross-Validation (Random Forest)\n - 4-fold CV Macro F1: 0.109 ± 0.011\n - Confirms weak generalization across classes.\n\n\n\n\nEvolution Modeling\n\n\nCode\n# =========================================================\n#Evolution below\n\nrate_cols = [\"A\",\"G\",\"O\",\"T\",\"V\",\"C\",\"F\",\"K\",\"M\",\"S\"]\n\n# build modeling matrix from evolution_ML\nX_rates_all = evolution_ML[rate_cols].copy()\nX_super_all = evolution_ML[[\"Superphylum_encoded\"]].copy()\ny_evo_all = evolution_ML[\"Superphylum_encoded\"].copy()   # &lt;— target is Superphylum now\n\n# log1p rates\nX_log_all = np.log1p(X_rates_all)\n\n# z-score rates\nscaler_evo = StandardScaler()\nX_scaled_all = scaler_evo.fit_transform(X_log_all)\n\n# stack with unscaled Superphylum code\nX_evo_all = X_scaled_all\n\n# stratified split 2:1 (1/3 test)\nX_train_evo, X_test_evo, y_train_evo, y_test_evo = train_test_split(\n    X_evo_all, y_evo_all, test_size=1/3, random_state=RANDOM_STATE, stratify=y_evo_all\n)\n\n# models\ndt_evo = DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight=\"balanced\")\nrf_evo = RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced_subsample\")\nlr_evo = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, class_weight=\"balanced\", multi_class=\"ovr\")\n\n# train & predict\ndt_evo.fit(X_train_evo, y_train_evo)\nrf_evo.fit(X_train_evo, y_train_evo)\nlr_evo.fit(X_train_evo, y_train_evo)  # already scaled representation\n\ndt_pred_evo = dt_evo.predict(X_test_evo)\nrf_pred_evo = rf_evo.predict(X_test_evo)\nlr_pred_evo = lr_evo.predict(X_test_evo)\n\nprint(\"\\n=== EVOLUTION RESULTS ===\")\nfor name, pred in [(\"Decision Tree\", dt_pred_evo), (\"Random Forest\", rf_pred_evo), (\"Logistic Regression\", lr_pred_evo)]:\n    acc = accuracy_score(y_test_evo, pred)\n    bal = balanced_accuracy_score(y_test_evo, pred)\n    f1m = f1_score(y_test_evo, pred, average=\"macro\")\n    print(f\"\\n{name}: acc={acc:.3f} | bal_acc={bal:.3f} | macro-F1={f1m:.3f}\")\n    print(classification_report(y_test_evo, pred, zero_division=0))\n    print(\"Confusion matrix:\\n\", confusion_matrix(y_test_evo, pred))\n\nmin_count_evo = pd.Series(y_evo_all).value_counts().min()\nif min_count_evo &gt;= 2:\n    n_splits_evo = int(min(5, min_count_evo))\n    cv_folds_evo = StratifiedKFold(n_splits=n_splits_evo, shuffle=True, random_state=RANDOM_STATE)\n    evo_cv_rf = cross_val_score(\n        RandomForestClassifier(random_state=RANDOM_STATE, class_weight=\"balanced_subsample\"),\n        X_evo_all, y_evo_all, cv=cv_folds_evo, scoring=\"f1_macro\"\n    )\n    print(f\"\\n[EVOLUTION] RF {n_splits_evo}-fold CV macro-F1: {evo_cv_rf.mean():.3f} ± {evo_cv_rf.std():.3f}\")\nelse:\n    print(\"\\n[EVOLUTION] Skipping CV: smallest class has &lt; 2 samples, cannot stratify.\")\n\n\n\n=== EVOLUTION RESULTS ===\n\nDecision Tree: acc=0.143 | bal_acc=0.229 | macro-F1=0.093\n              precision    recall  f1-score   support\n\n           0       0.12      1.00      0.21         3\n           1       0.00      0.00      0.00         4\n           2       0.00      0.00      0.00         3\n           3       1.00      0.14      0.25         7\n           4       0.00      0.00      0.00        11\n\n    accuracy                           0.14        28\n   macro avg       0.22      0.23      0.09        28\nweighted avg       0.26      0.14      0.09        28\n\nConfusion matrix:\n [[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  0  0  1]\n [ 5  0  1  1  0]\n [11  0  0  0  0]]\n\nRandom Forest: acc=0.214 | bal_acc=0.324 | macro-F1=0.232\n              precision    recall  f1-score   support\n\n           0       0.12      1.00      0.21         3\n           1       0.00      0.00      0.00         4\n           2       1.00      0.33      0.50         3\n           3       1.00      0.29      0.44         7\n           4       0.00      0.00      0.00        11\n\n    accuracy                           0.21        28\n   macro avg       0.42      0.32      0.23        28\nweighted avg       0.37      0.21      0.19        28\n\nConfusion matrix:\n [[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  1  0  0]\n [ 5  0  0  2  0]\n [11  0  0  0  0]]\n\nLogistic Regression: acc=0.500 | bal_acc=0.324 | macro-F1=0.311\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         3\n           1       0.00      0.00      0.00         4\n           2       1.00      0.33      0.50         3\n           3       1.00      0.29      0.44         7\n           4       0.44      1.00      0.61        11\n\n    accuracy                           0.50        28\n   macro avg       0.49      0.32      0.31        28\nweighted avg       0.53      0.50      0.40        28\n\nConfusion matrix:\n [[ 0  0  0  0  3]\n [ 0  0  0  0  4]\n [ 0  0  1  0  2]\n [ 0  0  0  2  5]\n [ 0  0  0  0 11]]\n\n\n\n[EVOLUTION] RF 5-fold CV macro-F1: 0.193 ± 0.065\n\n\n\n\nCode\nprint(\"\"\"\n=== EVOLUTION RESULTS ===\n\nDecision Tree: acc=0.143 | bal_acc=0.229 | macro-F1=0.093\nConfusion matrix:\n[[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  0  0  1]\n [ 5  0  1  1  0]\n [11  0  0  0  0]]\n\nRandom Forest: acc=0.214 | bal_acc=0.324 | macro-F1=0.232\nConfusion matrix:\n[[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  1  0  0]\n [ 5  0  0  2  0]\n [11  0  0  0  0]]\n\nLogistic Regression: acc=0.500 | bal_acc=0.324 | macro-F1=0.311\nConfusion matrix:\n[[ 0  0  0  0  3]\n [ 0  0  0  0  4]\n [ 0  0  1  0  2]\n [ 0  0  0  2  5]\n [ 0  0  0  0 11]]\n\n[EVOLUTION] RF 5-fold CV macro-F1: 0.193 ± 0.065\n\"\"\")\n\n\n\n=== EVOLUTION RESULTS ===\n\nDecision Tree: acc=0.143 | bal_acc=0.229 | macro-F1=0.093\nConfusion matrix:\n[[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  0  0  1]\n [ 5  0  1  1  0]\n [11  0  0  0  0]]\n\nRandom Forest: acc=0.214 | bal_acc=0.324 | macro-F1=0.232\nConfusion matrix:\n[[ 3  0  0  0  0]\n [ 4  0  0  0  0]\n [ 2  0  1  0  0]\n [ 5  0  0  2  0]\n [11  0  0  0  0]]\n\nLogistic Regression: acc=0.500 | bal_acc=0.324 | macro-F1=0.311\nConfusion matrix:\n[[ 0  0  0  0  3]\n [ 0  0  0  0  4]\n [ 0  0  1  0  2]\n [ 0  0  0  2  5]\n [ 0  0  0  0 11]]\n\n[EVOLUTION] RF 5-fold CV macro-F1: 0.193 ± 0.065\n\n\n\n\n\nSide-by-Side Comparison\n\n\nCode\n# =========================================================\n#side by side comparison\n\n#def _summ(dataset, name, y_true, y_pred):\ndef _summ(dataset, name, y_true, y_pred):\n    return {\n        \"dataset\": dataset,\n        \"model\": name,\n        \"acc\": accuracy_score(y_true, y_pred),\n        \"bal_acc\": balanced_accuracy_score(y_true, y_pred),\n        \"macro_F1\": f1_score(y_true, y_pred, average=\"macro\"),\n    }\n\n#rows\nrows = []\nrows += [\n    _summ(\"family\", \"Decision Tree\", y_test_fam, dt_pred_fam),\n    _summ(\"family\", \"Random Forest\", y_test_fam, rf_pred_fam),\n    _summ(\"family\", \"Logistic Regression\", y_test_fam, lr_pred_fam),\n]\nrows += [\n    _summ(\"evolution\", \"Decision Tree\", y_test_evo, dt_pred_evo),\n    _summ(\"evolution\", \"Random Forest\", y_test_evo, rf_pred_evo),\n    _summ(\"evolution\", \"Logistic Regression\", y_test_evo, lr_pred_evo),\n]\n\n#long → wide (one row per model, side-by-side metrics)\ncomp_long = pd.DataFrame(rows)\ncomp_wide = (\n    comp_long\n    .pivot(index=\"model\", columns=\"dataset\", values=[\"acc\", \"bal_acc\", \"macro_F1\"])\n    .sort_index()\n)\n\n#printing\nprint(\"\\n=== FAMILY vs EVOLUTION — MODEL COMPARISON ===\")\nprint(comp_wide.round(3))\n\n\n\n=== FAMILY vs EVOLUTION — MODEL COMPARISON ===\n                          acc          bal_acc         macro_F1       \ndataset             evolution family evolution family evolution family\nmodel                                                                 \nDecision Tree           0.143  0.147     0.229  0.280     0.093  0.087\nLogistic Regression     0.500  0.216     0.324  0.296     0.311  0.129\nRandom Forest           0.214  0.229     0.324  0.283     0.232  0.128\n\n\nOn the evolution data, logistic regression is best: 50% accuracy, macro-F1 ≈ 0.31, and balanced accuracy ≈ 0.324 (tied with random forest). Decision trees and random forests score lower on most measures. On the family data, all models perform poorly; macro-F1 is ~0.13 and balanced accuracy ~0.28–0.30, showing a tilt toward the majority class. In short, binary presence/absence traits don’t separate groups well, while rate-based features carry more signal—though still limited. Because the classes are uneven, macro-F1 and balanced accuracy give a clearer picture than plain accuracy. It means, accuracy is low and not reliable given the data issues seen in the EDA (imbalance, sparsity) explaining macro-F1 and balanced accuracy scores.\n\n\nSHAP Interpretability\n\n\nCode\n# =========================================================\n# SHAP interpretability\n\nshap.initjs()\n\n# -----------------------\n# FAMILY\n# -----------------------\nexplainer_fam = shap.TreeExplainer(rf_fam)\nshap_values_fam = explainer_fam.shap_values(X_test_fam)\n\nXtf = X_test_fam.values\nfn_fam = list(X_test_fam.columns)\n\n#Convert shap_values into consistent 2D form (N samples × F features)\n#If multi-class, aggregate absolute contributions across all classes\nif isinstance(shap_values_fam, list):\n    sv_fam = np.array(shap_values_fam)   # (C, N, F)\n    sv_fam = np.transpose(sv_fam, (1, 2, 0))  # (N, F, C)\nelif isinstance(shap_values_fam, np.ndarray) and shap_values_fam.ndim == 3:\n    sv_fam = shap_values_fam             # (N, F, C)\nelse:\n    sv_fam = np.array(shap_values_fam)   # (N, F)\n\n# Collapse to 2D by summing absolute contributions across classes\nif sv_fam.ndim == 3:\n    sv2d_fam = np.sum(np.abs(sv_fam), axis=2)  # (N, F)\nelse:\n    sv2d_fam = sv_fam\n\n#plots shap plot of family\nprint(\"\\n[SHAP] Random Forest — FAMILY\")\nshap.summary_plot(sv2d_fam, Xtf, feature_names=fn_fam, show=True)\n\n# quick text summary of the top contributors (mean |SHAP| per feature)\nfam_importance = np.abs(sv2d_fam).mean(axis=0)\nfam_top_idx = np.argsort(fam_importance)[::-1]\nprint(\"\\n[SHAP] FAMILY — top features by average absolute contribution\")\nfor rank in range(min(10, len(fn_fam))):\n    j = fam_top_idx[rank]\n    print(f\"{rank+1:&gt;2}. {fn_fam[j]}  —  mean|SHAP|={fam_importance[j]:.4f}\")\n\n# --------------------------\n# EVOLUTION\n# --------------------------\nexplainer_evo = shap.TreeExplainer(rf_evo)\nshap_values_evo = explainer_evo.shap_values(X_test_evo)\n\n# full names (used inside the model)\nevo_feature_names = [f\"log1p_{c}_z\" for c in rate_cols]\nXte = np.asarray(X_test_evo)\n\n# pretty names for display only\nevo_feature_pretty = rate_cols  # [\"A\",\"G\",\"O\",\"T\",\"V\",\"C\",\"F\",\"K\",\"M\",\"S\"]\n\n# Convert SHAP values into 2D array\nif isinstance(shap_values_evo, list):\n    sv_evo = np.array(shap_values_evo)           # (C, N, F)\n    sv_evo = np.transpose(sv_evo, (1, 2, 0))     # (N, F, C)\nelif isinstance(shap_values_evo, np.ndarray) and shap_values_evo.ndim == 3:\n    sv_evo = shap_values_evo                     # (N, F, C)\nelse:\n    sv_evo = np.array(shap_values_evo)           # (N, F)\n\n# collapse to 2D for global plot\nif sv_evo.ndim == 3:\n    sv2d_evo = np.sum(np.abs(sv_evo), axis=2)    # (N, F)\nelse:\n    sv2d_evo = sv_evo\n\n#SHAP summary plot with clean labels\nprint(\"\\n[SHAP] Random Forest — EVOLUTION (global)\")\nshap.summary_plot(sv2d_evo, Xte, feature_names=evo_feature_pretty, show=True)\n\n# quick text summary with clean labels\nevo_importance = np.abs(sv2d_evo).mean(axis=0)\nevo_top_idx = np.argsort(evo_importance)[::-1]\nprint(\"\\n[SHAP] EVOLUTION — top features by average absolute contribution\")\nfor rank in range(min(10, len(evo_feature_pretty))):\n    j = evo_top_idx[rank]\n    print(f\"{rank+1:&gt;2}. {evo_feature_pretty[j]}  —  mean|SHAP|={evo_importance[j]:.4f}\")\n      # (N, F)\n\n\n\n\n\n\n[SHAP] Random Forest — FAMILY\n\n\n\n\n\n\n\n\n\n\n[SHAP] FAMILY — top features by average absolute contribution\n 1. SS  —  mean|SHAP|=0.1858\n 2. F  —  mean|SHAP|=0.1131\n 3. T  —  mean|SHAP|=0.0595\n 4. C  —  mean|SHAP|=0.0525\n 5. M  —  mean|SHAP|=0.0441\n 6. V  —  mean|SHAP|=0.0289\n 7. O  —  mean|SHAP|=0.0192\n 8. A  —  mean|SHAP|=0.0158\n 9. G  —  mean|SHAP|=0.0062\n10. S  —  mean|SHAP|=0.0026\n\n[SHAP] Random Forest — EVOLUTION (global)\n\n\n\n\n\n\n\n\n\n\n[SHAP] EVOLUTION — top features by average absolute contribution\n 1. V  —  mean|SHAP|=0.0802\n 2. C  —  mean|SHAP|=0.0550\n 3. A  —  mean|SHAP|=0.0398\n 4. F  —  mean|SHAP|=0.0365\n 5. K  —  mean|SHAP|=0.0310\n 6. M  —  mean|SHAP|=0.0309\n 7. O  —  mean|SHAP|=0.0262\n 8. T  —  mean|SHAP|=0.0190\n 9. G  —  mean|SHAP|=0.0111\n10. S  —  mean|SHAP|=0.0089\n\n\n\nFor the family dataset, the single binary feature SS (sexual selection) dominates model predictions by a large margin, followed by traits like F (female choice) and T (territoriality). Most other traits have smaller and often negligible contributions. This suggests the model mostly keys off one or two strong binary indicators, which likely limits generalization.\nFor the evolution dataset, importance is spread across several continuous rate features. V (visual traits) has the largest average impact, followed by C (competition), A (acoustic), and F (female choice). Unlike family, no single variable dominates completely — instead, multiple rates contribute modestly, making predictions more balanced.\n\nOverall, the family model leans heavily on a few binary traits (especially SS), while the evolution model distributes influence across a wider set of rate-based features, indicating that continuous rates carry richer predictive signal even if the model’s raw accuracy remains modest."
  },
  {
    "objectID": "index.html#conclusion-and-interpretations",
    "href": "index.html#conclusion-and-interpretations",
    "title": "Abstract",
    "section": "Conclusion and Interpretations",
    "text": "Conclusion and Interpretations\nFamily_df (binary presence/absence)\nArthropoda makes up most of the data; most other phyla are small. Traits are very sparse. Only SS and F show up often. All models score low—trees and forests overfit, and logistic regression is also weak. SHAP shows SS drives most decisions, with F and a few others adding small effects. There isn’t enough signal to generalize due to sparsity and imbalanced classes.\nEvolution_df (rate-based traits) Phyla are roughly balanced, but the rate features are skewed and correlated. Logistic regression does best (~50% accuracy, highest macro-F1); trees and forests trail. SHAP spreads importance across V, C, A, and F—no single rate dominates. The signal is better than in the binary data, but still limited.\nOverall interpretation\nBinary presence/absence doesn’t separate groups well and pushes models to lean on SS. Rate-based features carry more usable signal and lead to more balanced decisions, but overall performance is still modest.\nImportant note for the project changes since the proposal:\nCompared to the proposal, the project shifted from predicting at the class/family level to using superphyla to reduce sparsity. Evolutionary rates were log-transformed and standardized instead of binarized, and evaluation emphasized balanced accuracy and macro F1 rather than ROC-AUC. Lastly, SHAP, originally planned as a secondary tool, became central in confirming trait reliance patterns across datasets."
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Trait-Based Prediction of Animal Taxa",
    "section": "",
    "text": "Evolution Data:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 84 entries, 0 to 83\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Tree    84 non-null     int64  \n 1   Phylum  84 non-null     object \n 2   A       84 non-null     float64\n 3   G       84 non-null     float64\n 4   O       84 non-null     float64\n 5   T       84 non-null     float64\n 6   V       84 non-null     float64\n 7   C       84 non-null     float64\n 8   F       84 non-null     float64\n 9   K       84 non-null     float64\n 10  M       84 non-null     float64\n 11  S       84 non-null     float64\ndtypes: float64(10), int64(1), object(1)\nmemory usage: 8.0+ KB\nNone\n\nFamily Data:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1087 entries, 0 to 1086\nData columns (total 13 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Tree_Label  1087 non-null   object\n 1   Phylum      1087 non-null   object\n 2   SS          1087 non-null   int64 \n 3   A           1087 non-null   int64 \n 4   G           1087 non-null   int64 \n 5   O           1087 non-null   int64 \n 6   T           1087 non-null   int64 \n 7   V           1087 non-null   int64 \n 8   C           1087 non-null   int64 \n 9   F           1087 non-null   int64 \n 10  K           1087 non-null   int64 \n 11  M           1087 non-null   int64 \n 12  S           1087 non-null   int64 \ndtypes: int64(11), object(2)\nmemory usage: 110.5+ KB\nNone\n\n\nFamily-related metadata: 1 indicates trait presence, a whereas 0 indicates trait absence. SS: Combined (any sexually selected trait), A: Auditory, G: Gustatory, O: Olfactory, T:Tactile, V: Visual, C: Male-male competition, F: Female choice, K: Female-female competition, M: Male choice, S: Intersexual conflict.\nRates of trait evolution metadata: A: Auditory, G: Gustatory, O:Olfactory, T:Tactile, V: Visual, C: Male-male competition, F: Female choice, K: Female-female competition, M: Male choice, S: Intersexual conflict.\n\n\n1. Evolution Rate Dataset\n- File: animals_rateof_evolution.csv\n- Dimensions: 84 rows × 12 columns\n- Description: Contains continuous values representing the evolutionary rate of various sexual traits across different animal taxa.\n2. Family-Level Trait Dataset\n- File: family-related_data.csv\n- Dimensions: 1087 rows × 13 columns\n- Description: Encodes presence (1) or absence (0) of various sexually selected traits (e.g., visual, auditory, male-male competition) at the family level.\n\n\nI chose these two datasets because the family-related data contains binary values (0 or 1) for various sexually selected traits, which makes it good for training machine learning models across a wide range of animal families. This gives me hands-on experience with multi-class classification and feature selection, and I may use SHAP to interpret the model’s predictions and feature contributions depending on how the models perform. The evolutionary rates data, on the other hand, includes continuous values (some zeros and some greater than zero), which lets me compare whether binary presence/absence data or continuous evolutionary rates give better predictive power. The phylum-level data seems more redundant with the family-level data, but the evolutionary rates dataset provides a different kind of information. Even though it is model-derived, I can still use the rates as input features to predict superphyla classes, since they reflect repeated origins of sexually selected traits across lineages.\nBoth datasets have a large number of distinct phyla. To reduce sparsity and improve interpretability, I will group these into higher-level clades called superphyla. This grouping stays below the kingdom level (since all taxa fall under Animalia) but still captures important evolutionary structure. Specifically, I will classify them into:\n\nEcdysozoa\nLophotrochozoa\nDeuterostomia\nBasal Metazoa & Non-Bilaterians\nBasal Bilateria\n\nSo overall, the family-level dataset gives raw binary trait data, while the evolutionary rates dataset gives continuous, model-derived estimates of trait origins. Using both together lets me compare which type of data—binary or continuous—works better for predicting evolutionary groupings.\nDataset Source: https://frontiersin.figshare.com/articles/dataset/Data_Sheet_3_Evolution_of_sexually_selected_traits_across_animals_XLSX/21921510?file=38886321\n(DataCite) Citation: Tuschhoff, E.; Wiens, John J. (2023). Data_Sheet_3_Evolution of sexually selected traits across animals.XLSX. Frontiers. Dataset. https://doi.org/10.3389/fevo.2023.1042747.s003\nOther Sources:\n“Animal.” Wikipedia, 16 Aug. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Animal&oldid=1306191709.\nCollins, Allen G., et al. “Phylogenetic Context and Basal Metazoan Model Systems.” Integrative and Comparative Biology, vol. 45, no. 4, Aug. 2005, pp. 585–94. academic.oup.com, https://doi.org/10.1093/icb/45.4.585.\n“Deuterostome.” Wikipedia, 9 Jul. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Deuterostome&oldid=1299664913.\n“Ecdysozoa.” Wikipedia, 12 Aug. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Ecdysozoa&oldid=1305526962.\n“Lophotrochozoa.” Wikipedia, 26 Jul. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Lophotrochozoa&oldid=1302526625."
  },
  {
    "objectID": "proposal.html#dataset",
    "href": "proposal.html#dataset",
    "title": "Trait-Based Prediction of Animal Taxa",
    "section": "",
    "text": "Evolution Data:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 84 entries, 0 to 83\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Tree    84 non-null     int64  \n 1   Phylum  84 non-null     object \n 2   A       84 non-null     float64\n 3   G       84 non-null     float64\n 4   O       84 non-null     float64\n 5   T       84 non-null     float64\n 6   V       84 non-null     float64\n 7   C       84 non-null     float64\n 8   F       84 non-null     float64\n 9   K       84 non-null     float64\n 10  M       84 non-null     float64\n 11  S       84 non-null     float64\ndtypes: float64(10), int64(1), object(1)\nmemory usage: 8.0+ KB\nNone\n\nFamily Data:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1087 entries, 0 to 1086\nData columns (total 13 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Tree_Label  1087 non-null   object\n 1   Phylum      1087 non-null   object\n 2   SS          1087 non-null   int64 \n 3   A           1087 non-null   int64 \n 4   G           1087 non-null   int64 \n 5   O           1087 non-null   int64 \n 6   T           1087 non-null   int64 \n 7   V           1087 non-null   int64 \n 8   C           1087 non-null   int64 \n 9   F           1087 non-null   int64 \n 10  K           1087 non-null   int64 \n 11  M           1087 non-null   int64 \n 12  S           1087 non-null   int64 \ndtypes: int64(11), object(2)\nmemory usage: 110.5+ KB\nNone\n\n\nFamily-related metadata: 1 indicates trait presence, a whereas 0 indicates trait absence. SS: Combined (any sexually selected trait), A: Auditory, G: Gustatory, O: Olfactory, T:Tactile, V: Visual, C: Male-male competition, F: Female choice, K: Female-female competition, M: Male choice, S: Intersexual conflict.\nRates of trait evolution metadata: A: Auditory, G: Gustatory, O:Olfactory, T:Tactile, V: Visual, C: Male-male competition, F: Female choice, K: Female-female competition, M: Male choice, S: Intersexual conflict.\n\n\n1. Evolution Rate Dataset\n- File: animals_rateof_evolution.csv\n- Dimensions: 84 rows × 12 columns\n- Description: Contains continuous values representing the evolutionary rate of various sexual traits across different animal taxa.\n2. Family-Level Trait Dataset\n- File: family-related_data.csv\n- Dimensions: 1087 rows × 13 columns\n- Description: Encodes presence (1) or absence (0) of various sexually selected traits (e.g., visual, auditory, male-male competition) at the family level.\n\n\nI chose these two datasets because the family-related data contains binary values (0 or 1) for various sexually selected traits, which makes it good for training machine learning models across a wide range of animal families. This gives me hands-on experience with multi-class classification and feature selection, and I may use SHAP to interpret the model’s predictions and feature contributions depending on how the models perform. The evolutionary rates data, on the other hand, includes continuous values (some zeros and some greater than zero), which lets me compare whether binary presence/absence data or continuous evolutionary rates give better predictive power. The phylum-level data seems more redundant with the family-level data, but the evolutionary rates dataset provides a different kind of information. Even though it is model-derived, I can still use the rates as input features to predict superphyla classes, since they reflect repeated origins of sexually selected traits across lineages.\nBoth datasets have a large number of distinct phyla. To reduce sparsity and improve interpretability, I will group these into higher-level clades called superphyla. This grouping stays below the kingdom level (since all taxa fall under Animalia) but still captures important evolutionary structure. Specifically, I will classify them into:\n\nEcdysozoa\nLophotrochozoa\nDeuterostomia\nBasal Metazoa & Non-Bilaterians\nBasal Bilateria\n\nSo overall, the family-level dataset gives raw binary trait data, while the evolutionary rates dataset gives continuous, model-derived estimates of trait origins. Using both together lets me compare which type of data—binary or continuous—works better for predicting evolutionary groupings.\nDataset Source: https://frontiersin.figshare.com/articles/dataset/Data_Sheet_3_Evolution_of_sexually_selected_traits_across_animals_XLSX/21921510?file=38886321\n(DataCite) Citation: Tuschhoff, E.; Wiens, John J. (2023). Data_Sheet_3_Evolution of sexually selected traits across animals.XLSX. Frontiers. Dataset. https://doi.org/10.3389/fevo.2023.1042747.s003\nOther Sources:\n“Animal.” Wikipedia, 16 Aug. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Animal&oldid=1306191709.\nCollins, Allen G., et al. “Phylogenetic Context and Basal Metazoan Model Systems.” Integrative and Comparative Biology, vol. 45, no. 4, Aug. 2005, pp. 585–94. academic.oup.com, https://doi.org/10.1093/icb/45.4.585.\n“Deuterostome.” Wikipedia, 9 Jul. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Deuterostome&oldid=1299664913.\n“Ecdysozoa.” Wikipedia, 12 Aug. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Ecdysozoa&oldid=1305526962.\n“Lophotrochozoa.” Wikipedia, 26 Jul. 2025. Wikipedia, https://en.wikipedia.org/w/index.php?title=Lophotrochozoa&oldid=1302526625."
  },
  {
    "objectID": "proposal.html#motivation",
    "href": "proposal.html#motivation",
    "title": "Trait-Based Prediction of Animal Taxa",
    "section": "Motivation",
    "text": "Motivation\nI was motivated to try out the machine learning-based project with the animal classification because there are challenges to accurately classify each animal based on characteristics such as physiology, geographical distribution, and other traits, and even down to genomic sequence similarity (Tessler et al., 2022; van der Gulik et al., 2023). The idea of using machine learning for taxonomic classification already existed, but it still seems like a fairly new approach, so I wanted to evaluate how effective machine learning can be in this area (Alipour et al., 2024). If the project works out, it could be a stepping stone for further tweaks and improvements before applying it to more taxonomic classification problems using various numeric traits in a practical setting. This would help narrow down more relevant relative candidates when classifying while also saving time assuming the model accuracy is good.\nSources:\nAlipour, Fatemeh, et al. “Leveraging Machine Learning for Taxonomic Classification of Emerging Astroviruses.” Frontiers in Molecular Biosciences, vol. 10, Jan. 2024. Frontiers, https://doi.org/10.3389/fmolb.2023.1305506.\nTessler, Michael, et al. “Phylogenomics and the First Higher Taxonomy of Placozoa, an Ancient and Enigmatic Animal Phylum.” Frontiers in Ecology and Evolution, vol. 10, Dec. 2022. Frontiers, https://doi.org/10.3389/fevo.2022.1016357.\nvan der Gulik, Peter T. S., et al. “Renewing Linnaean Taxonomy: A Proposal to Restructure the Highest Levels of the Natural System.” Biological Reviews, vol. 98, no. 2, 2023, pp. 584–602. Wiley Online Library, https://doi.org/10.1111/brv.12920."
  },
  {
    "objectID": "proposal.html#questions",
    "href": "proposal.html#questions",
    "title": "Trait-Based Prediction of Animal Taxa",
    "section": "Questions",
    "text": "Questions\n\nHow accurately can a machine learning model classify animal taxa based on the binary presence of sexually selected traits?\nDo evolutionary origin rates of sexual traits provide stronger predictive power than binary trait presence when classifying animal taxa?"
  },
  {
    "objectID": "proposal.html#analysis-plan",
    "href": "proposal.html#analysis-plan",
    "title": "Trait-Based Prediction of Animal Taxa",
    "section": "Analysis plan",
    "text": "Analysis plan\n\nOverview\nThe primary objective is to assess and compare the predictive power and interpretability of both data.\n\n\nDataset Descriptions\n1. Family-Level Trait Data (family_df)\n\nFormat: Binary indicators (0 or 1) for the presence or absence of sexually selected traits.\nTraits include: SS, A, G, O, T, V, C, F, K, M, S\nEach row represents a taxonomic family.\nThe target variable will likely be a categorical label such as Class or a user-defined taxon.\n\n2. Evolutionary Rates Data (evolution_df)\n\nFormat: Continuous numerical values representing the origin rates of the same traits listed above.\nEach row represents a taxonomic group.\nTarget variable will match the one used in the binary dataset for comparison.\n\n\n\nExploratory Data Analysis (EDA)\nEDA will be performed separately for both datasets:\n\nDistribution plots for each trait in histogram\nVisualization of binary presence in sexually selected traits if possible\nCorrelation matrix of sexually selected traits related to each other\nSummary statistics for continuous traits.\nCount plots or bar charts showing trait prevalence by taxonomic group (e.g., class or family).\n\n\n\nModeling Approach\nFor both datasets:\n1. Data Preparation\n\nI will double check for any null values.\nI will encode target variable (animals taxa) using LabelEncoder. For the evolutionary rates, I will convert any values &gt; 0 to 1 and hot-encode these numerical columns (sexually selected traits) for the presence of sexually selected traits.\nFor evolution_df, I will standardize these sexually selected traits feature using StandardScaler.\n\n2. Models to Use\n\nDecisionTreeClassifier\nRandomForestClassifier\nLogisticRegression\n\n3. Evaluation Metrics\n\nAccuracy score\nConfusion matrix\nClassification report\nCross-validation score (cross_val_score)\nROC-AUC score\n\n4. Model Interpretation\n\nI will use SHAP to interpret trained models.\nI will generate SHAP summary plots and bar plots to highlight influential traits.\nI will compare interpretability between models trained on binary and continuous data for the evolutionary rates.\n\n\n\nComparison and Interpretation\n\nI will interpret the classification performance across both data and answer both questions. Then, I will draw conclusions about which dataset format (binary or continuous) provides stronger predictive insights for question #2.\nI will analyze SHAP outputs to identify which traits contribute most to predictions.\nI may also interpret which family has sexually selected traits and explain the results (if I have more time during the presentation)."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Family-level dataset: Contains 1,087 rows. Binary (0/1) presence/absence data for various sexually selected traits at the family level, each linked to a phylum.\n\nEvolutionary rates dataset: Contains 84 rows. Continuous values estimating the origin rates of sexually selected traits at the phylum level, based on discrete maximum likelihood analyses."
  },
  {
    "objectID": "data.html#variable-names-and-descriptions",
    "href": "data.html#variable-names-and-descriptions",
    "title": "Data",
    "section": "Variable Names and Descriptions",
    "text": "Variable Names and Descriptions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nTree_Label\nIdentifier linking families to the phylogenetic tree (string)\n\n\nPhylum\nTaxonomic phylum name (string)\n\n\nSS\nPresence of any sexually selected trait (0 = absent, 1 = present)\n\n\nA\nAuditory trait (0/1)\n\n\nG\nGustatory trait (0/1)\n\n\nO\nOlfactory trait (0/1)\n\n\nT\nTactile trait (0/1)\n\n\nV\nVisual trait (0/1)\n\n\nC\nMale-male competition trait (0/1)\n\n\nF\nFemale choice trait (0/1)\n\n\nK\nFemale-female competition trait (0/1)\n\n\nM\nMale choice trait (0/1)\n\n\nS\nIntersexual conflict trait (0/1)"
  },
  {
    "objectID": "data.html#data-types",
    "href": "data.html#data-types",
    "title": "Data",
    "section": "Data Types",
    "text": "Data Types\n\n\n\nColumn\nData Type\n\n\n\n\nTree_Label\nobject (string)\n\n\nPhylum\nobject (string)\n\n\nSS, A, G, O, T, V, C, F, K, M, S\nint64 (binary: 0 or 1)"
  },
  {
    "objectID": "data.html#variable-names-and-descriptions-1",
    "href": "data.html#variable-names-and-descriptions-1",
    "title": "Data",
    "section": "Variable Names and Descriptions",
    "text": "Variable Names and Descriptions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nTree\nIdentifier for phylogenetic tree replicate (integer)\n\n\nPhylum\nTaxonomic phylum name (string)\n\n\nA\nRate of origin for auditory traits (float)\n\n\nG\nRate of origin for gustatory traits (float)\n\n\nO\nRate of origin for olfactory traits (float)\n\n\nT\nRate of origin for tactile traits (float)\n\n\nV\nRate of origin for visual traits (float)\n\n\nC\nRate of origin for male-male competition traits (float)\n\n\nF\nRate of origin for female choice traits (float)\n\n\nK\nRate of origin for female-female competition traits (float)\n\n\nM\nRate of origin for male choice traits (float)\n\n\nS\nRate of origin for intersexual conflict traits (float)"
  },
  {
    "objectID": "data.html#data-types-1",
    "href": "data.html#data-types-1",
    "title": "Data",
    "section": "Data Types",
    "text": "Data Types\n\n\n\n\n\n\n\nColumn\nData Type\n\n\n\n\nTree\nint64 (integer)\n\n\nPhylum\nobject (string)\n\n\nA, G, O, T, V, C, F, K, M, S\nfloat64 (continuous, ≥ 0, with some zeros)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSource: https://frontiersin.figshare.com/articles/dataset/Data_Sheet_3_Evolution_of_sexually_selected_traits_across_animals_XLSX/21921510?file=38886321"
  }
]